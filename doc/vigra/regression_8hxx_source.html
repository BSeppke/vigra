<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><TITLE>vigra - vigra/regression.hxx Source File</TITLE>
<link rel=stylesheet type="text/css" href="vigra.css">
<link rel=stylesheet type="text/css" href="vigra_1_8_2.css">
<link rel="shortcut icon" href="vigra-icon.ico" />
<script type="text/javascript">
function toggleHiddenDocumentation( textID, toggleID, toggleMessage )
{ 
	if( document.getElementById(textID).style.display == 'none' )
    {
		document.getElementById(textID).style.display = 'block';
        document.getElementById(toggleID).innerHTML = "hide " + toggleMessage;
    }
    else
    {
		document.getElementById(textID).style.display = 'none';
        document.getElementById(toggleID).innerHTML = "show " + toggleMessage;
	}
    return false;
}
</script>
</head>
<body  bgcolor="#f8f0e0" link="#0040b0" vlink="#a00040">
<basefont face="Helvetica,Arial,sans-serif" size=3>
<p align=right>
[ <a href="http://hci.iwr.uni-heidelberg.de/vigra/">VIGRA Homepage</a> |
 <a href="functionindex.html">Function Index</a> |
 <a href="classes.html">Class Index</a> |
 <a href="namespaces.html">Namespaces</a> |
 <a href="files.html">File List</a> |
 <a href="index.html">Main Page</a> ]
</p>
<!-- Generated by Doxygen 1.7.6.1 -->
</div>
<div class="contents">
<table class="main_heading">
<tr>
<td width="100%">vigra/regression.hxx
</td>
<td align=right><a href="http://hci.iwr.uni-heidelberg.de/vigra/"><IMG border=0 ALT="VIGRA" SRC="documents/vigra.gif" title="VIGRA Homepage"></a></td></tr>
</table><p>

<div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">/************************************************************************/</span>
<a name="l00002"></a>00002 <span class="comment">/*                                                                      */</span>
<a name="l00003"></a>00003 <span class="comment">/*             Copyright 2008-2013 by Ullrich Koethe                    */</span>
<a name="l00004"></a>00004 <span class="comment">/*                                                                      */</span>
<a name="l00005"></a>00005 <span class="comment">/*    This file is part of the VIGRA computer vision library.           */</span>
<a name="l00006"></a>00006 <span class="comment">/*    The VIGRA Website is                                              */</span>
<a name="l00007"></a>00007 <span class="comment">/*        http://hci.iwr.uni-heidelberg.de/vigra/                       */</span>
<a name="l00008"></a>00008 <span class="comment">/*    Please direct questions, bug reports, and contributions to        */</span>
<a name="l00009"></a>00009 <span class="comment">/*        ullrich.koethe@iwr.uni-heidelberg.de    or                    */</span>
<a name="l00010"></a>00010 <span class="comment">/*        vigra@informatik.uni-hamburg.de                               */</span>
<a name="l00011"></a>00011 <span class="comment">/*                                                                      */</span>
<a name="l00012"></a>00012 <span class="comment">/*    Permission is hereby granted, free of charge, to any person       */</span>
<a name="l00013"></a>00013 <span class="comment">/*    obtaining a copy of this software and associated documentation    */</span>
<a name="l00014"></a>00014 <span class="comment">/*    files (the &quot;Software&quot;), to deal in the Software without           */</span>
<a name="l00015"></a>00015 <span class="comment">/*    restriction, including without limitation the rights to use,      */</span>
<a name="l00016"></a>00016 <span class="comment">/*    copy, modify, merge, publish, distribute, sublicense, and/or      */</span>
<a name="l00017"></a>00017 <span class="comment">/*    sell copies of the Software, and to permit persons to whom the    */</span>
<a name="l00018"></a>00018 <span class="comment">/*    Software is furnished to do so, subject to the following          */</span>
<a name="l00019"></a>00019 <span class="comment">/*    conditions:                                                       */</span>
<a name="l00020"></a>00020 <span class="comment">/*                                                                      */</span>
<a name="l00021"></a>00021 <span class="comment">/*    The above copyright notice and this permission notice shall be    */</span>
<a name="l00022"></a>00022 <span class="comment">/*    included in all copies or substantial portions of the             */</span>
<a name="l00023"></a>00023 <span class="comment">/*    Software.                                                         */</span>
<a name="l00024"></a>00024 <span class="comment">/*                                                                      */</span>
<a name="l00025"></a>00025 <span class="comment">/*    THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND    */</span>
<a name="l00026"></a>00026 <span class="comment">/*    EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES   */</span>
<a name="l00027"></a>00027 <span class="comment">/*    OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND          */</span>
<a name="l00028"></a>00028 <span class="comment">/*    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT       */</span>
<a name="l00029"></a>00029 <span class="comment">/*    HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,      */</span>
<a name="l00030"></a>00030 <span class="comment">/*    WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING      */</span>
<a name="l00031"></a>00031 <span class="comment">/*    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR     */</span>
<a name="l00032"></a>00032 <span class="comment">/*    OTHER DEALINGS IN THE SOFTWARE.                                   */</span>
<a name="l00033"></a>00033 <span class="comment">/*                                                                      */</span>
<a name="l00034"></a>00034 <span class="comment">/************************************************************************/</span>
<a name="l00035"></a>00035 
<a name="l00036"></a>00036 
<a name="l00037"></a>00037 <span class="preprocessor">#ifndef VIGRA_REGRESSION_HXX</span>
<a name="l00038"></a>00038 <span class="preprocessor"></span><span class="preprocessor">#define VIGRA_REGRESSION_HXX</span>
<a name="l00039"></a>00039 <span class="preprocessor"></span>
<a name="l00040"></a>00040 <span class="preprocessor">#include &quot;matrix.hxx&quot;</span>
<a name="l00041"></a>00041 <span class="preprocessor">#include &quot;linear_solve.hxx&quot;</span>
<a name="l00042"></a>00042 <span class="preprocessor">#include &quot;singular_value_decomposition.hxx&quot;</span>
<a name="l00043"></a>00043 <span class="preprocessor">#include &quot;numerictraits.hxx&quot;</span>
<a name="l00044"></a>00044 <span class="preprocessor">#include &quot;functorexpression.hxx&quot;</span>
<a name="l00045"></a>00045 <span class="preprocessor">#include &quot;autodiff.hxx&quot;</span>
<a name="l00046"></a>00046 
<a name="l00047"></a>00047 
<a name="l00048"></a>00048 <span class="keyword">namespace </span>vigra
<a name="l00049"></a>00049 {
<a name="l00050"></a>00050 
<a name="l00051"></a>00051 <span class="keyword">namespace </span>linalg
<a name="l00052"></a>00052 {
<a name="l00053"></a>00053 <span class="comment"></span>
<a name="l00054"></a>00054 <span class="comment">/** \addtogroup Optimization Optimization and Regression</span>
<a name="l00055"></a>00055 <span class="comment"> */</span><span class="comment"></span>
<a name="l00056"></a>00056 <span class="comment">//@{</span>
<a name="l00057"></a>00057 <span class="comment"></span><span class="comment">   /** Ordinary Least Squares Regression.</span>
<a name="l00058"></a>00058 <span class="comment"></span>
<a name="l00059"></a>00059 <span class="comment">       Given a matrix \a A with &lt;tt&gt;m&lt;/tt&gt; rows and &lt;tt&gt;n&lt;/tt&gt; columns (with &lt;tt&gt;m &gt;= n&lt;/tt&gt;),</span>
<a name="l00060"></a>00060 <span class="comment">       and a column vector \a b of length &lt;tt&gt;m&lt;/tt&gt; rows, this function computes</span>
<a name="l00061"></a>00061 <span class="comment">       the column vector \a x of length &lt;tt&gt;n&lt;/tt&gt; rows that solves the optimization problem</span>
<a name="l00062"></a>00062 <span class="comment"></span>
<a name="l00063"></a>00063 <span class="comment">        \f[ \tilde \textrm{\bf x} = \textrm{argmin}</span>
<a name="l00064"></a>00064 <span class="comment">            \left|\left|\textrm{\bf A} \textrm{\bf x} - \textrm{\bf b}\right|\right|_2^2</span>
<a name="l00065"></a>00065 <span class="comment">        \f]</span>
<a name="l00066"></a>00066 <span class="comment"></span>
<a name="l00067"></a>00067 <span class="comment">       When \a b is a matrix with &lt;tt&gt;k&lt;/tt&gt; columns, \a x must also have</span>
<a name="l00068"></a>00068 <span class="comment">       &lt;tt&gt;k&lt;/tt&gt; columns, which will contain the solutions for the corresponding columns of</span>
<a name="l00069"></a>00069 <span class="comment">       \a b. Note that all matrices must already have the correct shape.</span>
<a name="l00070"></a>00070 <span class="comment"></span>
<a name="l00071"></a>00071 <span class="comment">       This function is just another name for \ref linearSolve(), perhaps</span>
<a name="l00072"></a>00072 <span class="comment">       leading to more readable code when \a A is a rectangular matrix. It returns</span>
<a name="l00073"></a>00073 <span class="comment">       &lt;tt&gt;false&lt;/tt&gt; when the rank of \a A is less than &lt;tt&gt;n&lt;/tt&gt;.</span>
<a name="l00074"></a>00074 <span class="comment">       See \ref linearSolve() for more documentation.</span>
<a name="l00075"></a>00075 <span class="comment"></span>
<a name="l00076"></a>00076 <span class="comment">       &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;&lt;br/&gt;</span>
<a name="l00077"></a>00077 <span class="comment">       Namespaces: vigra and vigra::linalg</span>
<a name="l00078"></a>00078 <span class="comment">   */</span>
<a name="l00079"></a>00079 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> C3&gt;
<a name="l00080"></a>00080 <span class="keyword">inline</span> <span class="keywordtype">bool</span>
<a name="l00081"></a><a class="code" href="group__Optimization.html#gab3be347f5631d0aa2ee74c07479e0383">00081</a> <a class="code" href="group__Optimization.html#gab3be347f5631d0aa2ee74c07479e0383">leastSquares</a>(<a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C1&gt;</a> <span class="keyword">const</span> &amp; A,
<a name="l00082"></a>00082              <a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C2&gt;</a> <span class="keyword">const</span> &amp;b, <a class="code" href="classvigra_1_1MultiArrayView.html" title="Base class for, and view to, vigra::MultiArray.">MultiArrayView&lt;2, T, C3&gt;</a> &amp;x,
<a name="l00083"></a>00083              std::string method = <span class="stringliteral">&quot;QR&quot;</span>)
<a name="l00084"></a>00084 {
<a name="l00085"></a>00085     <span class="keywordflow">return</span> <a class="code" href="group__MatrixAlgebra.html#ga889fc66edb20976e31a9212a073e411f">linearSolve</a>(A, b, x, method);
<a name="l00086"></a>00086 }
<a name="l00087"></a>00087 <span class="comment"></span>
<a name="l00088"></a>00088 <span class="comment">   /** Weighted Least Squares Regression.</span>
<a name="l00089"></a>00089 <span class="comment"></span>
<a name="l00090"></a>00090 <span class="comment">       Given a matrix \a A with &lt;tt&gt;m&lt;/tt&gt; rows and &lt;tt&gt;n&lt;/tt&gt; columns (with &lt;tt&gt;m &gt;= n&lt;/tt&gt;),</span>
<a name="l00091"></a>00091 <span class="comment">       a vector \a b of length &lt;tt&gt;m&lt;/tt&gt;, and a weight vector \a weights of length &lt;tt&gt;m&lt;/tt&gt;</span>
<a name="l00092"></a>00092 <span class="comment">       with non-negative entries, this function computes the vector \a x of length &lt;tt&gt;n&lt;/tt&gt;</span>
<a name="l00093"></a>00093 <span class="comment">       that solves the optimization problem</span>
<a name="l00094"></a>00094 <span class="comment"></span>
<a name="l00095"></a>00095 <span class="comment">        \f[ \tilde \textrm{\bf x} = \textrm{argmin}</span>
<a name="l00096"></a>00096 <span class="comment">            \left(\textrm{\bf A} \textrm{\bf x} - \textrm{\bf b}\right)^T</span>
<a name="l00097"></a>00097 <span class="comment">             \textrm{diag}(\textrm{\bf weights})</span>
<a name="l00098"></a>00098 <span class="comment">             \left(\textrm{\bf A} \textrm{\bf x} - \textrm{\bf b}\right)</span>
<a name="l00099"></a>00099 <span class="comment">        \f]</span>
<a name="l00100"></a>00100 <span class="comment"></span>
<a name="l00101"></a>00101 <span class="comment">       where &lt;tt&gt;diag(weights)&lt;/tt&gt; creates a diagonal matrix from \a weights.</span>
<a name="l00102"></a>00102 <span class="comment">       The algorithm calls \ref leastSquares() on the equivalent problem</span>
<a name="l00103"></a>00103 <span class="comment"></span>
<a name="l00104"></a>00104 <span class="comment">        \f[ \tilde \textrm{\bf x} = \textrm{argmin}</span>
<a name="l00105"></a>00105 <span class="comment">             \left|\left|\textrm{diag}(\textrm{\bf weights})^{1/2}\textrm{\bf A} \textrm{\bf x} -</span>
<a name="l00106"></a>00106 <span class="comment">                  \textrm{diag}(\textrm{\bf weights})^{1/2} \textrm{\bf b}\right|\right|_2^2</span>
<a name="l00107"></a>00107 <span class="comment">        \f]</span>
<a name="l00108"></a>00108 <span class="comment"></span>
<a name="l00109"></a>00109 <span class="comment">       where the square root of \a weights is just taken element-wise.</span>
<a name="l00110"></a>00110 <span class="comment"></span>
<a name="l00111"></a>00111 <span class="comment">       When \a b is a matrix with &lt;tt&gt;k&lt;/tt&gt; columns, \a x must also have</span>
<a name="l00112"></a>00112 <span class="comment">       &lt;tt&gt;k&lt;/tt&gt; columns, which will contain the solutions for the corresponding columns of</span>
<a name="l00113"></a>00113 <span class="comment">       \a b. Note that all matrices must already have the correct shape.</span>
<a name="l00114"></a>00114 <span class="comment"></span>
<a name="l00115"></a>00115 <span class="comment">       The function returns</span>
<a name="l00116"></a>00116 <span class="comment">       &lt;tt&gt;false&lt;/tt&gt; when the rank of the weighted matrix \a A is less than &lt;tt&gt;n&lt;/tt&gt;.</span>
<a name="l00117"></a>00117 <span class="comment"></span>
<a name="l00118"></a>00118 <span class="comment">       &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;&lt;br/&gt;</span>
<a name="l00119"></a>00119 <span class="comment">       Namespaces: vigra and vigra::linalg</span>
<a name="l00120"></a>00120 <span class="comment">   */</span>
<a name="l00121"></a>00121 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> C3, <span class="keyword">class</span> C4&gt;
<a name="l00122"></a>00122 <span class="keywordtype">bool</span>
<a name="l00123"></a><a class="code" href="group__Optimization.html#ga591ca4f43e4114253d7bfa2953f07c4d">00123</a> <a class="code" href="group__Optimization.html#ga591ca4f43e4114253d7bfa2953f07c4d">weightedLeastSquares</a>(<a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C1&gt;</a> <span class="keyword">const</span> &amp; A,
<a name="l00124"></a>00124              <a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C2&gt;</a> <span class="keyword">const</span> &amp;b, <a class="code" href="classvigra_1_1MultiArrayView.html" title="Base class for, and view to, vigra::MultiArray.">MultiArrayView&lt;2, T, C3&gt;</a> <span class="keyword">const</span> &amp;weights,
<a name="l00125"></a>00125              <a class="code" href="classvigra_1_1MultiArrayView.html" title="Base class for, and view to, vigra::MultiArray.">MultiArrayView&lt;2, T, C4&gt;</a> &amp;x, std::string method = <span class="stringliteral">&quot;QR&quot;</span>)
<a name="l00126"></a>00126 {
<a name="l00127"></a>00127     <span class="keyword">typedef</span> T Real;
<a name="l00128"></a>00128 
<a name="l00129"></a>00129     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> rows = <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(A);
<a name="l00130"></a>00130     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cols = <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(A);
<a name="l00131"></a>00131     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> rhsCount = <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(b);
<a name="l00132"></a>00132     vigra_precondition(rows &gt;= cols,
<a name="l00133"></a>00133        <span class="stringliteral">&quot;weightedLeastSquares(): Input matrix A must be rectangular with rowCount &gt;= columnCount.&quot;</span>);
<a name="l00134"></a>00134     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(b) == rows,
<a name="l00135"></a>00135        <span class="stringliteral">&quot;weightedLeastSquares(): Shape mismatch between matrices A and b.&quot;</span>);
<a name="l00136"></a>00136     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(b) == <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(weights) &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(weights) == 1,
<a name="l00137"></a>00137        <span class="stringliteral">&quot;weightedLeastSquares(): Weight matrix has wrong shape.&quot;</span>);
<a name="l00138"></a>00138     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(x) == cols &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(x) == rhsCount,
<a name="l00139"></a>00139        <span class="stringliteral">&quot;weightedLeastSquares(): Result matrix x has wrong shape.&quot;</span>);
<a name="l00140"></a>00140 
<a name="l00141"></a>00141     <a class="code" href="classvigra_1_1linalg_1_1Matrix.html">Matrix&lt;T&gt;</a> wa(A.<a class="code" href="classvigra_1_1MultiArrayView.html#a53c8f0d5c70f10f31fbc246cbe524e32">shape</a>()), wb(b.<a class="code" href="classvigra_1_1MultiArrayView.html#a53c8f0d5c70f10f31fbc246cbe524e32">shape</a>());
<a name="l00142"></a>00142 
<a name="l00143"></a>00143     <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k=0; k&lt;rows; ++k)
<a name="l00144"></a>00144     {
<a name="l00145"></a>00145         vigra_precondition(weights(k,0) &gt;= 0,
<a name="l00146"></a>00146            <span class="stringliteral">&quot;weightedLeastSquares(): Weights must be positive.&quot;</span>);
<a name="l00147"></a>00147         T w = <a class="code" href="group__LinearAlgebraFunctions.html#ga04ac28305eb14c42937b447c874518cd">std::sqrt</a>(weights(k,0));
<a name="l00148"></a>00148         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> l=0; l&lt;cols; ++l)
<a name="l00149"></a>00149             wa(k,l) = w * A(k,l);
<a name="l00150"></a>00150         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> l=0; l&lt;rhsCount; ++l)
<a name="l00151"></a>00151             wb(k,l) = w * b(k,l);
<a name="l00152"></a>00152     }
<a name="l00153"></a>00153 
<a name="l00154"></a>00154     <span class="keywordflow">return</span> <a class="code" href="group__Optimization.html#gab3be347f5631d0aa2ee74c07479e0383">leastSquares</a>(wa, wb, x, method);
<a name="l00155"></a>00155 }
<a name="l00156"></a>00156 <span class="comment"></span>
<a name="l00157"></a>00157 <span class="comment">   /** Ridge Regression.</span>
<a name="l00158"></a>00158 <span class="comment"></span>
<a name="l00159"></a>00159 <span class="comment">       Given a matrix \a A with &lt;tt&gt;m&lt;/tt&gt; rows and &lt;tt&gt;n&lt;/tt&gt; columns (with &lt;tt&gt;m &gt;= n&lt;/tt&gt;),</span>
<a name="l00160"></a>00160 <span class="comment">       a vector \a b of length &lt;tt&gt;m&lt;/tt&gt;, and a regularization parameter &lt;tt&gt;lambda &gt;= 0.0&lt;/tt&gt;,</span>
<a name="l00161"></a>00161 <span class="comment">       this function computes the vector \a x of length &lt;tt&gt;n&lt;/tt&gt;</span>
<a name="l00162"></a>00162 <span class="comment">       that solves the optimization problem</span>
<a name="l00163"></a>00163 <span class="comment"></span>
<a name="l00164"></a>00164 <span class="comment">        \f[ \tilde \textrm{\bf x} = \textrm{argmin}</span>
<a name="l00165"></a>00165 <span class="comment">            \left|\left|\textrm{\bf A} \textrm{\bf x} - \textrm{\bf b}\right|\right|_2^2 +</span>
<a name="l00166"></a>00166 <span class="comment">            \lambda \textrm{\bf x}^T\textrm{\bf x}</span>
<a name="l00167"></a>00167 <span class="comment">        \f]</span>
<a name="l00168"></a>00168 <span class="comment"></span>
<a name="l00169"></a>00169 <span class="comment">       This is implemented by means of \ref singularValueDecomposition().</span>
<a name="l00170"></a>00170 <span class="comment"></span>
<a name="l00171"></a>00171 <span class="comment">       When \a b is a matrix with &lt;tt&gt;k&lt;/tt&gt; columns, \a x must also have</span>
<a name="l00172"></a>00172 <span class="comment">       &lt;tt&gt;k&lt;/tt&gt; columns, which will contain the solutions for the corresponding columns of</span>
<a name="l00173"></a>00173 <span class="comment">       \a b. Note that all matrices must already have the correct shape.</span>
<a name="l00174"></a>00174 <span class="comment"></span>
<a name="l00175"></a>00175 <span class="comment">       The function returns &lt;tt&gt;false&lt;/tt&gt; if the rank of \a A is less than &lt;tt&gt;n&lt;/tt&gt;</span>
<a name="l00176"></a>00176 <span class="comment">       and &lt;tt&gt;lambda == 0.0&lt;/tt&gt;.</span>
<a name="l00177"></a>00177 <span class="comment"></span>
<a name="l00178"></a>00178 <span class="comment">       &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;&lt;br/&gt;</span>
<a name="l00179"></a>00179 <span class="comment">       Namespaces: vigra and vigra::linalg</span>
<a name="l00180"></a>00180 <span class="comment">   */</span>
<a name="l00181"></a>00181 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> C3&gt;
<a name="l00182"></a>00182 <span class="keywordtype">bool</span>
<a name="l00183"></a><a class="code" href="group__Optimization.html#ga647810e9f3f2ff2e401f410b4855c58a">00183</a> <a class="code" href="group__Optimization.html#ga647810e9f3f2ff2e401f410b4855c58a">ridgeRegression</a>(<a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C1&gt;</a> <span class="keyword">const</span> &amp; A,
<a name="l00184"></a>00184                 <a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C2&gt;</a> <span class="keyword">const</span> &amp;b, <a class="code" href="classvigra_1_1MultiArrayView.html" title="Base class for, and view to, vigra::MultiArray.">MultiArrayView&lt;2, T, C3&gt;</a> &amp;x, <span class="keywordtype">double</span> lambda)
<a name="l00185"></a>00185 {
<a name="l00186"></a>00186     <span class="keyword">typedef</span> T Real;
<a name="l00187"></a>00187 
<a name="l00188"></a>00188     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> rows = <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(A);
<a name="l00189"></a>00189     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cols = <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(A);
<a name="l00190"></a>00190     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> rhsCount = <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(b);
<a name="l00191"></a>00191     vigra_precondition(rows &gt;= cols,
<a name="l00192"></a>00192        <span class="stringliteral">&quot;ridgeRegression(): Input matrix A must be rectangular with rowCount &gt;= columnCount.&quot;</span>);
<a name="l00193"></a>00193     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(b) == rows,
<a name="l00194"></a>00194        <span class="stringliteral">&quot;ridgeRegression(): Shape mismatch between matrices A and b.&quot;</span>);
<a name="l00195"></a>00195     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(x) == cols &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(x) == rhsCount,
<a name="l00196"></a>00196        <span class="stringliteral">&quot;ridgeRegression(): Result matrix x has wrong shape.&quot;</span>);
<a name="l00197"></a>00197     vigra_precondition(lambda &gt;= 0.0,
<a name="l00198"></a>00198        <span class="stringliteral">&quot;ridgeRegression(): lambda &gt;= 0.0 required.&quot;</span>);
<a name="l00199"></a>00199 
<a name="l00200"></a>00200     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> m = rows;
<a name="l00201"></a>00201     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> n = cols;
<a name="l00202"></a>00202 
<a name="l00203"></a>00203     <a class="code" href="classvigra_1_1linalg_1_1Matrix.html">Matrix&lt;T&gt;</a> u(m, n), s(n, 1), v(n, n);
<a name="l00204"></a>00204 
<a name="l00205"></a>00205     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> rank = <a class="code" href="group__MatrixAlgebra.html#gaf20e05edcc344f32d96fdaf5a6b3b972">singularValueDecomposition</a>(A, u, s, v);
<a name="l00206"></a>00206     <span class="keywordflow">if</span>(rank &lt; n &amp;&amp; lambda == 0.0)
<a name="l00207"></a>00207         <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00208"></a>00208 
<a name="l00209"></a>00209     <a class="code" href="classvigra_1_1linalg_1_1Matrix.html">Matrix&lt;T&gt;</a> t = <a class="code" href="group__LinearAlgebraFunctions.html#ga38a88300083908488d85348c0cf4d3ff">transpose</a>(u)*b;
<a name="l00210"></a>00210     <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k=0; k&lt;cols; ++k)
<a name="l00211"></a>00211         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> l=0; l&lt;rhsCount; ++l)
<a name="l00212"></a>00212             t(k,l) *= s(k,0) / (<a class="code" href="group__LinearAlgebraFunctions.html#ga9ab478f0a88c5174f28260163a1a6de9">sq</a>(s(k,0)) + lambda);
<a name="l00213"></a>00213     x = v*t;
<a name="l00214"></a>00214     <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00215"></a>00215 }
<a name="l00216"></a>00216 <span class="comment"></span>
<a name="l00217"></a>00217 <span class="comment">   /** Weighted ridge Regression.</span>
<a name="l00218"></a>00218 <span class="comment"></span>
<a name="l00219"></a>00219 <span class="comment">       Given a matrix \a A with &lt;tt&gt;m&lt;/tt&gt; rows and &lt;tt&gt;n&lt;/tt&gt; columns (with &lt;tt&gt;m &gt;= n&lt;/tt&gt;),</span>
<a name="l00220"></a>00220 <span class="comment">       a vector \a b of length &lt;tt&gt;m&lt;/tt&gt;, a weight vector \a weights of length &lt;tt&gt;m&lt;/tt&gt;</span>
<a name="l00221"></a>00221 <span class="comment">       with non-negative entries, and a regularization parameter &lt;tt&gt;lambda &gt;= 0.0&lt;/tt&gt;</span>
<a name="l00222"></a>00222 <span class="comment">       this function computes the vector \a x of length &lt;tt&gt;n&lt;/tt&gt;</span>
<a name="l00223"></a>00223 <span class="comment">       that solves the optimization problem</span>
<a name="l00224"></a>00224 <span class="comment"></span>
<a name="l00225"></a>00225 <span class="comment">        \f[ \tilde \textrm{\bf x} = \textrm{argmin}</span>
<a name="l00226"></a>00226 <span class="comment">            \left(\textrm{\bf A} \textrm{\bf x} - \textrm{\bf b}\right)^T</span>
<a name="l00227"></a>00227 <span class="comment">             \textrm{diag}(\textrm{\bf weights})</span>
<a name="l00228"></a>00228 <span class="comment">             \left(\textrm{\bf A} \textrm{\bf x} - \textrm{\bf b}\right) +</span>
<a name="l00229"></a>00229 <span class="comment">             \lambda \textrm{\bf x}^T\textrm{\bf x}</span>
<a name="l00230"></a>00230 <span class="comment">        \f]</span>
<a name="l00231"></a>00231 <span class="comment"></span>
<a name="l00232"></a>00232 <span class="comment">       where &lt;tt&gt;diag(weights)&lt;/tt&gt; creates a diagonal matrix from \a weights.</span>
<a name="l00233"></a>00233 <span class="comment">       The algorithm calls \ref ridgeRegression() on the equivalent problem</span>
<a name="l00234"></a>00234 <span class="comment"></span>
<a name="l00235"></a>00235 <span class="comment">        \f[ \tilde \textrm{\bf x} = \textrm{argmin}</span>
<a name="l00236"></a>00236 <span class="comment">            \left|\left|\textrm{diag}(\textrm{\bf weights})^{1/2}\textrm{\bf A} \textrm{\bf x} -</span>
<a name="l00237"></a>00237 <span class="comment">                  \textrm{diag}(\textrm{\bf weights})^{1/2} \textrm{\bf b}\right|\right|_2^2 +</span>
<a name="l00238"></a>00238 <span class="comment">             \lambda \textrm{\bf x}^T\textrm{\bf x}</span>
<a name="l00239"></a>00239 <span class="comment">        \f]</span>
<a name="l00240"></a>00240 <span class="comment"></span>
<a name="l00241"></a>00241 <span class="comment">       where the square root of \a weights is just taken element-wise.  This solution is</span>
<a name="l00242"></a>00242 <span class="comment">       computed by means of \ref singularValueDecomposition().</span>
<a name="l00243"></a>00243 <span class="comment"></span>
<a name="l00244"></a>00244 <span class="comment">       When \a b is a matrix with &lt;tt&gt;k&lt;/tt&gt; columns, \a x must also have</span>
<a name="l00245"></a>00245 <span class="comment">       &lt;tt&gt;k&lt;/tt&gt; columns, which will contain the solutions for the corresponding columns of</span>
<a name="l00246"></a>00246 <span class="comment">       \a b. Note that all matrices must already have the correct shape.</span>
<a name="l00247"></a>00247 <span class="comment"></span>
<a name="l00248"></a>00248 <span class="comment">       The function returns &lt;tt&gt;false&lt;/tt&gt; if the rank of \a A is less than &lt;tt&gt;n&lt;/tt&gt;</span>
<a name="l00249"></a>00249 <span class="comment">       and &lt;tt&gt;lambda == 0.0&lt;/tt&gt;.</span>
<a name="l00250"></a>00250 <span class="comment"></span>
<a name="l00251"></a>00251 <span class="comment">       &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;&lt;br/&gt;</span>
<a name="l00252"></a>00252 <span class="comment">       Namespaces: vigra and vigra::linalg</span>
<a name="l00253"></a>00253 <span class="comment">   */</span>
<a name="l00254"></a>00254 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> C3, <span class="keyword">class</span> C4&gt;
<a name="l00255"></a>00255 <span class="keywordtype">bool</span>
<a name="l00256"></a><a class="code" href="group__Optimization.html#gade6eb7c915e0e6b1820974316b1d5d32">00256</a> <a class="code" href="group__Optimization.html#gade6eb7c915e0e6b1820974316b1d5d32">weightedRidgeRegression</a>(<a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C1&gt;</a> <span class="keyword">const</span> &amp; A,
<a name="l00257"></a>00257              <a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C2&gt;</a> <span class="keyword">const</span> &amp;b, <a class="code" href="classvigra_1_1MultiArrayView.html" title="Base class for, and view to, vigra::MultiArray.">MultiArrayView&lt;2, T, C3&gt;</a> <span class="keyword">const</span> &amp;weights,
<a name="l00258"></a>00258              <a class="code" href="classvigra_1_1MultiArrayView.html" title="Base class for, and view to, vigra::MultiArray.">MultiArrayView&lt;2, T, C4&gt;</a> &amp;x, <span class="keywordtype">double</span> lambda)
<a name="l00259"></a>00259 {
<a name="l00260"></a>00260     <span class="keyword">typedef</span> T Real;
<a name="l00261"></a>00261 
<a name="l00262"></a>00262     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> rows = <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(A);
<a name="l00263"></a>00263     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cols = <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(A);
<a name="l00264"></a>00264     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> rhsCount = <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(b);
<a name="l00265"></a>00265     vigra_precondition(rows &gt;= cols,
<a name="l00266"></a>00266        <span class="stringliteral">&quot;weightedRidgeRegression(): Input matrix A must be rectangular with rowCount &gt;= columnCount.&quot;</span>);
<a name="l00267"></a>00267     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(b) == rows,
<a name="l00268"></a>00268        <span class="stringliteral">&quot;weightedRidgeRegression(): Shape mismatch between matrices A and b.&quot;</span>);
<a name="l00269"></a>00269     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(b) == <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(weights) &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(weights) == 1,
<a name="l00270"></a>00270        <span class="stringliteral">&quot;weightedRidgeRegression(): Weight matrix has wrong shape.&quot;</span>);
<a name="l00271"></a>00271     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(x) == cols &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(x) == rhsCount,
<a name="l00272"></a>00272        <span class="stringliteral">&quot;weightedRidgeRegression(): Result matrix x has wrong shape.&quot;</span>);
<a name="l00273"></a>00273     vigra_precondition(lambda &gt;= 0.0,
<a name="l00274"></a>00274        <span class="stringliteral">&quot;weightedRidgeRegression(): lambda &gt;= 0.0 required.&quot;</span>);
<a name="l00275"></a>00275 
<a name="l00276"></a>00276     <a class="code" href="classvigra_1_1linalg_1_1Matrix.html">Matrix&lt;T&gt;</a> wa(A.<a class="code" href="classvigra_1_1MultiArrayView.html#a53c8f0d5c70f10f31fbc246cbe524e32">shape</a>()), wb(b.<a class="code" href="classvigra_1_1MultiArrayView.html#a53c8f0d5c70f10f31fbc246cbe524e32">shape</a>());
<a name="l00277"></a>00277 
<a name="l00278"></a>00278     <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k=0; k&lt;rows; ++k)
<a name="l00279"></a>00279     {
<a name="l00280"></a>00280         vigra_precondition(weights(k,0) &gt;= 0,
<a name="l00281"></a>00281            <span class="stringliteral">&quot;weightedRidgeRegression(): Weights must be positive.&quot;</span>);
<a name="l00282"></a>00282         T w = <a class="code" href="group__LinearAlgebraFunctions.html#ga04ac28305eb14c42937b447c874518cd">std::sqrt</a>(weights(k,0));
<a name="l00283"></a>00283         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> l=0; l&lt;cols; ++l)
<a name="l00284"></a>00284             wa(k,l) = w * A(k,l);
<a name="l00285"></a>00285         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> l=0; l&lt;rhsCount; ++l)
<a name="l00286"></a>00286             wb(k,l) = w * b(k,l);
<a name="l00287"></a>00287     }
<a name="l00288"></a>00288 
<a name="l00289"></a>00289     <span class="keywordflow">return</span> <a class="code" href="group__Optimization.html#ga647810e9f3f2ff2e401f410b4855c58a">ridgeRegression</a>(wa, wb, x, lambda);
<a name="l00290"></a>00290 }
<a name="l00291"></a>00291 <span class="comment"></span>
<a name="l00292"></a>00292 <span class="comment">   /** Ridge Regression with many lambdas.</span>
<a name="l00293"></a>00293 <span class="comment"></span>
<a name="l00294"></a>00294 <span class="comment">       This executes \ref ridgeRegression() for a sequence of regularization parameters. This</span>
<a name="l00295"></a>00295 <span class="comment">       is implemented so that the \ref singularValueDecomposition() has to be executed only once.</span>
<a name="l00296"></a>00296 <span class="comment">       \a lambda must be an array conforming to the &lt;tt&gt;std::vector&lt;/tt&gt; interface, i.e. must</span>
<a name="l00297"></a>00297 <span class="comment">       support &lt;tt&gt;lambda.size()&lt;/tt&gt; and &lt;tt&gt;lambda[k]&lt;/tt&gt;. The columns of the matrix \a x</span>
<a name="l00298"></a>00298 <span class="comment">       will contain the solutions for the corresponding lambda, so the  number of columns of</span>
<a name="l00299"></a>00299 <span class="comment">       the matrix \a x must be equal to &lt;tt&gt;lambda.size()&lt;/tt&gt;, and \a b must be a columns vector,</span>
<a name="l00300"></a>00300 <span class="comment">       i.e. cannot contain several right hand sides at once.</span>
<a name="l00301"></a>00301 <span class="comment"></span>
<a name="l00302"></a>00302 <span class="comment">       The function returns &lt;tt&gt;false&lt;/tt&gt; when the matrix \a A is rank deficient. If this</span>
<a name="l00303"></a>00303 <span class="comment">       happens, and one of the lambdas is zero, the corresponding column of \a x will be skipped.</span>
<a name="l00304"></a>00304 <span class="comment"></span>
<a name="l00305"></a>00305 <span class="comment">       &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;&lt;br/&gt;</span>
<a name="l00306"></a>00306 <span class="comment">       Namespaces: vigra and vigra::linalg</span>
<a name="l00307"></a>00307 <span class="comment">   */</span>
<a name="l00308"></a>00308 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> C3, <span class="keyword">class</span> Array&gt;
<a name="l00309"></a>00309 <span class="keywordtype">bool</span>
<a name="l00310"></a><a class="code" href="group__Optimization.html#gad20a4d83649e2c65d9d553105882af9f">00310</a> <a class="code" href="group__Optimization.html#gad20a4d83649e2c65d9d553105882af9f">ridgeRegressionSeries</a>(<a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C1&gt;</a> <span class="keyword">const</span> &amp; A,
<a name="l00311"></a>00311           <a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C2&gt;</a> <span class="keyword">const</span> &amp;b, <a class="code" href="classvigra_1_1MultiArrayView.html" title="Base class for, and view to, vigra::MultiArray.">MultiArrayView&lt;2, T, C3&gt;</a> &amp;x, Array <span class="keyword">const</span> &amp; lambda)
<a name="l00312"></a>00312 {
<a name="l00313"></a>00313     <span class="keyword">typedef</span> T Real;
<a name="l00314"></a>00314 
<a name="l00315"></a>00315     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> rows = <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(A);
<a name="l00316"></a>00316     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cols = <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(A);
<a name="l00317"></a>00317     <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> lambdaCount = lambda.size();
<a name="l00318"></a>00318     vigra_precondition(rows &gt;= cols,
<a name="l00319"></a>00319        <span class="stringliteral">&quot;ridgeRegressionSeries(): Input matrix A must be rectangular with rowCount &gt;= columnCount.&quot;</span>);
<a name="l00320"></a>00320     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(b) == rows &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(b) == 1,
<a name="l00321"></a>00321        <span class="stringliteral">&quot;ridgeRegressionSeries(): Shape mismatch between matrices A and b.&quot;</span>);
<a name="l00322"></a>00322     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(x) == cols &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(x) == lambdaCount,
<a name="l00323"></a>00323        <span class="stringliteral">&quot;ridgeRegressionSeries(): Result matrix x has wrong shape.&quot;</span>);
<a name="l00324"></a>00324 
<a name="l00325"></a>00325     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> m = rows;
<a name="l00326"></a>00326     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> n = cols;
<a name="l00327"></a>00327 
<a name="l00328"></a>00328     <a class="code" href="classvigra_1_1linalg_1_1Matrix.html">Matrix&lt;T&gt;</a> u(m, n), s(n, 1), v(n, n);
<a name="l00329"></a>00329 
<a name="l00330"></a>00330     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> rank = <a class="code" href="group__MatrixAlgebra.html#gaf20e05edcc344f32d96fdaf5a6b3b972">singularValueDecomposition</a>(A, u, s, v);
<a name="l00331"></a>00331 
<a name="l00332"></a>00332     <a class="code" href="classvigra_1_1linalg_1_1Matrix.html">Matrix&lt;T&gt;</a> xl = <a class="code" href="group__LinearAlgebraFunctions.html#ga38a88300083908488d85348c0cf4d3ff">transpose</a>(u)*b;
<a name="l00333"></a>00333     <a class="code" href="classvigra_1_1linalg_1_1Matrix.html">Matrix&lt;T&gt;</a> xt(cols,1);
<a name="l00334"></a>00334     <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i=0; i&lt;lambdaCount; ++i)
<a name="l00335"></a>00335     {
<a name="l00336"></a>00336         vigra_precondition(lambda[i] &gt;= 0.0,
<a name="l00337"></a>00337            <span class="stringliteral">&quot;ridgeRegressionSeries(): lambda &gt;= 0.0 required.&quot;</span>);
<a name="l00338"></a>00338         <span class="keywordflow">if</span>(lambda[i] == 0.0 &amp;&amp; rank &lt; rows)
<a name="l00339"></a>00339             <span class="keywordflow">continue</span>;
<a name="l00340"></a>00340         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k=0; k&lt;cols; ++k)
<a name="l00341"></a>00341             xt(k,0) = xl(k,0) * s(k,0) / (<a class="code" href="group__LinearAlgebraFunctions.html#ga9ab478f0a88c5174f28260163a1a6de9">sq</a>(s(k,0)) + lambda[i]);
<a name="l00342"></a>00342         <a class="code" href="group__LinearAlgebraFunctions.html#gab8ee32ac1c1c77108435f22be5cb08a0">columnVector</a>(x, i) = v*xt;
<a name="l00343"></a>00343     }
<a name="l00344"></a>00344     <span class="keywordflow">return</span> (rank == n);
<a name="l00345"></a>00345 }
<a name="l00346"></a>00346 <span class="comment"></span>
<a name="l00347"></a>00347 <span class="comment">/** \brief Pass options to leastAngleRegression().</span>
<a name="l00348"></a>00348 <span class="comment"></span>
<a name="l00349"></a>00349 <span class="comment">    &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;&lt;br/&gt;</span>
<a name="l00350"></a>00350 <span class="comment">    Namespaces: vigra and vigra::linalg</span>
<a name="l00351"></a>00351 <span class="comment">*/</span>
<a name="l00352"></a><a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html">00352</a> <span class="keyword">class </span><a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html" title="Pass options to leastAngleRegression().">LeastAngleRegressionOptions</a>
<a name="l00353"></a>00353 {
<a name="l00354"></a>00354   <span class="keyword">public</span>:
<a name="l00355"></a>00355     <span class="keyword">enum</span> Mode { LARS, LASSO, NNLASSO };
<a name="l00356"></a>00356 <span class="comment"></span>
<a name="l00357"></a>00357 <span class="comment">        /** Initialize all options with default values.</span>
<a name="l00358"></a>00358 <span class="comment">        */</span>
<a name="l00359"></a><a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#a857b414e001f5d5f2f357ad1ba6b7297">00359</a>     <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#a857b414e001f5d5f2f357ad1ba6b7297">LeastAngleRegressionOptions</a>()
<a name="l00360"></a>00360     : max_solution_count(0),
<a name="l00361"></a>00361       unconstrained_dimension_count(0),
<a name="l00362"></a>00362       mode(LASSO),
<a name="l00363"></a>00363       least_squares_solutions(true)
<a name="l00364"></a>00364     {}
<a name="l00365"></a>00365 <span class="comment"></span>
<a name="l00366"></a>00366 <span class="comment">        /** Maximum number of solutions to be computed.</span>
<a name="l00367"></a>00367 <span class="comment"></span>
<a name="l00368"></a>00368 <span class="comment">            If \a n is 0 (the default), the number of solutions is determined by the length</span>
<a name="l00369"></a>00369 <span class="comment">            of the solution array. Otherwise, the minimum of maxSolutionCount() and that</span>
<a name="l00370"></a>00370 <span class="comment">            length is taken.&lt;br&gt;</span>
<a name="l00371"></a>00371 <span class="comment">            Default: 0 (use length of solution array)</span>
<a name="l00372"></a>00372 <span class="comment">        */</span>
<a name="l00373"></a><a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#a7d09e52d484f5aced17987ef9a9ea1bd">00373</a>     <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html" title="Pass options to leastAngleRegression().">LeastAngleRegressionOptions</a> &amp; <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#a7d09e52d484f5aced17987ef9a9ea1bd">maxSolutionCount</a>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> n)
<a name="l00374"></a>00374     {
<a name="l00375"></a>00375         max_solution_count = (int)n;
<a name="l00376"></a>00376         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
<a name="l00377"></a>00377     }
<a name="l00378"></a>00378 <span class="comment"></span>
<a name="l00379"></a>00379 <span class="comment">        /** Set the mode of the algorithm.</span>
<a name="l00380"></a>00380 <span class="comment"></span>
<a name="l00381"></a>00381 <span class="comment">            Mode must be one of &quot;lars&quot;, &quot;lasso&quot;, &quot;nnlasso&quot;. The function just calls</span>
<a name="l00382"></a>00382 <span class="comment">            the member function of the corresponding name to set the mode.</span>
<a name="l00383"></a>00383 <span class="comment"></span>
<a name="l00384"></a>00384 <span class="comment">            Default: &quot;lasso&quot;</span>
<a name="l00385"></a>00385 <span class="comment">        */</span>
<a name="l00386"></a><a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#ab8a57eca5fbf53a5daaa26f8bf261ead">00386</a>     <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html" title="Pass options to leastAngleRegression().">LeastAngleRegressionOptions</a> &amp; <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#ab8a57eca5fbf53a5daaa26f8bf261ead">setMode</a>(std::string mode)
<a name="l00387"></a>00387     {
<a name="l00388"></a>00388         mode = <a class="code" href="namespacevigra.html#ad49e6891f1cd7d62bda19b2d3099f04d">tolower</a>(mode);
<a name="l00389"></a>00389         <span class="keywordflow">if</span>(mode == <span class="stringliteral">&quot;lars&quot;</span>)
<a name="l00390"></a>00390             this-&gt;<a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#aede22ea3ca20637290b3b3f1589e467f">lars</a>();
<a name="l00391"></a>00391         <span class="keywordflow">else</span> <span class="keywordflow">if</span>(mode == <span class="stringliteral">&quot;lasso&quot;</span>)
<a name="l00392"></a>00392             this-&gt;<a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#acaf3bd267d5d659368770b92bb37a6b7">lasso</a>();
<a name="l00393"></a>00393         <span class="keywordflow">else</span> <span class="keywordflow">if</span>(mode == <span class="stringliteral">&quot;nnlasso&quot;</span>)
<a name="l00394"></a>00394             this-&gt;<a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#a7d732a5ef3bc9181382b0b0e491d3221">nnlasso</a>();
<a name="l00395"></a>00395         <span class="keywordflow">else</span>
<a name="l00396"></a>00396             vigra_fail(<span class="stringliteral">&quot;LeastAngleRegressionOptions.setMode(): Invalid mode.&quot;</span>);
<a name="l00397"></a>00397         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
<a name="l00398"></a>00398     }
<a name="l00399"></a>00399 
<a name="l00400"></a>00400 <span class="comment"></span>
<a name="l00401"></a>00401 <span class="comment">        /** Use the plain LARS algorithm.</span>
<a name="l00402"></a>00402 <span class="comment"></span>
<a name="l00403"></a>00403 <span class="comment">            Default: inactive</span>
<a name="l00404"></a>00404 <span class="comment">        */</span>
<a name="l00405"></a><a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#aede22ea3ca20637290b3b3f1589e467f">00405</a>     <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html" title="Pass options to leastAngleRegression().">LeastAngleRegressionOptions</a> &amp; <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#aede22ea3ca20637290b3b3f1589e467f">lars</a>()
<a name="l00406"></a>00406     {
<a name="l00407"></a>00407         mode = LARS;
<a name="l00408"></a>00408         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
<a name="l00409"></a>00409     }
<a name="l00410"></a>00410 <span class="comment"></span>
<a name="l00411"></a>00411 <span class="comment">        /** Use the LASSO modification of the LARS algorithm.</span>
<a name="l00412"></a>00412 <span class="comment"></span>
<a name="l00413"></a>00413 <span class="comment">            This allows features to be removed from the active set under certain conditions.&lt;br&gt;</span>
<a name="l00414"></a>00414 <span class="comment">            Default: active</span>
<a name="l00415"></a>00415 <span class="comment">        */</span>
<a name="l00416"></a><a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#acaf3bd267d5d659368770b92bb37a6b7">00416</a>     <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html" title="Pass options to leastAngleRegression().">LeastAngleRegressionOptions</a> &amp; <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#acaf3bd267d5d659368770b92bb37a6b7">lasso</a>()
<a name="l00417"></a>00417     {
<a name="l00418"></a>00418         mode = LASSO;
<a name="l00419"></a>00419         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
<a name="l00420"></a>00420     }
<a name="l00421"></a>00421 <span class="comment"></span>
<a name="l00422"></a>00422 <span class="comment">        /** Use the non-negative LASSO modification of the LARS algorithm.</span>
<a name="l00423"></a>00423 <span class="comment"></span>
<a name="l00424"></a>00424 <span class="comment">            This enforces all non-zero entries in the solution to be positive.&lt;br&gt;</span>
<a name="l00425"></a>00425 <span class="comment">            Default: inactive</span>
<a name="l00426"></a>00426 <span class="comment">        */</span>
<a name="l00427"></a><a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#a7d732a5ef3bc9181382b0b0e491d3221">00427</a>     <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html" title="Pass options to leastAngleRegression().">LeastAngleRegressionOptions</a> &amp; <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#a7d732a5ef3bc9181382b0b0e491d3221">nnlasso</a>()
<a name="l00428"></a>00428     {
<a name="l00429"></a>00429         mode = NNLASSO;
<a name="l00430"></a>00430         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
<a name="l00431"></a>00431     }
<a name="l00432"></a>00432 <span class="comment"></span>
<a name="l00433"></a>00433 <span class="comment">        /** Compute least squares solutions.</span>
<a name="l00434"></a>00434 <span class="comment"></span>
<a name="l00435"></a>00435 <span class="comment">            Use least angle regression to determine active sets, but</span>
<a name="l00436"></a>00436 <span class="comment">            return least squares solutions for the features in each active set,</span>
<a name="l00437"></a>00437 <span class="comment">            instead of constrained solutions.&lt;br&gt;</span>
<a name="l00438"></a>00438 <span class="comment">            Default: &lt;tt&gt;true&lt;/tt&gt;</span>
<a name="l00439"></a>00439 <span class="comment">        */</span>
<a name="l00440"></a><a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#ace0ea38e4ecc228ec83004e96ddc4fae">00440</a>     <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html" title="Pass options to leastAngleRegression().">LeastAngleRegressionOptions</a> &amp; <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html#ace0ea38e4ecc228ec83004e96ddc4fae">leastSquaresSolutions</a>(<span class="keywordtype">bool</span> select = <span class="keyword">true</span>)
<a name="l00441"></a>00441     {
<a name="l00442"></a>00442         least_squares_solutions = select;
<a name="l00443"></a>00443         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
<a name="l00444"></a>00444     }
<a name="l00445"></a>00445 
<a name="l00446"></a>00446     <span class="keywordtype">int</span> max_solution_count, unconstrained_dimension_count;
<a name="l00447"></a>00447     Mode mode;
<a name="l00448"></a>00448     <span class="keywordtype">bool</span> least_squares_solutions;
<a name="l00449"></a>00449 };
<a name="l00450"></a>00450 
<a name="l00451"></a>00451 <span class="keyword">namespace </span>detail {
<a name="l00452"></a>00452 
<a name="l00453"></a>00453 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2&gt;
<a name="l00454"></a>00454 <span class="keyword">struct </span>LarsData
<a name="l00455"></a>00455 {
<a name="l00456"></a>00456     <span class="keyword">typedef</span> <span class="keyword">typename</span> <a class="code" href="classvigra_1_1TinyVector.html" title="Class for fixed size vectors.This class contains an array of size SIZE of the specified VALUETYPE...">MultiArrayShape&lt;2&gt;::type</a> Shape;
<a name="l00457"></a>00457 
<a name="l00458"></a>00458     <span class="keywordtype">int</span> activeSetSize;
<a name="l00459"></a>00459     <a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C1&gt;</a> A;
<a name="l00460"></a>00460     <a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C2&gt;</a> b;
<a name="l00461"></a>00461     Matrix&lt;T&gt; R, qtb, lars_solution, lars_prediction, next_lsq_solution, next_lsq_prediction, searchVector;
<a name="l00462"></a>00462     <a class="code" href="classvigra_1_1ArrayVector.html">ArrayVector&lt;MultiArrayIndex&gt;</a> columnPermutation;
<a name="l00463"></a>00463 
<a name="l00464"></a>00464     <span class="comment">// init data for a new run</span>
<a name="l00465"></a>00465     LarsData(<a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C1&gt;</a> <span class="keyword">const</span> &amp; Ai, <a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C2&gt;</a> <span class="keyword">const</span> &amp; bi)
<a name="l00466"></a>00466     : activeSetSize(1),
<a name="l00467"></a>00467       A(Ai), b(bi), R(A), qtb(b),
<a name="l00468"></a>00468       lars_solution(A.shape(1), 1), lars_prediction(A.shape(0), 1),
<a name="l00469"></a>00469       next_lsq_solution(A.shape(1), 1), next_lsq_prediction(A.shape(0), 1), searchVector(A.shape(0), 1),
<a name="l00470"></a>00470       columnPermutation(A.shape(1))
<a name="l00471"></a>00471     {
<a name="l00472"></a>00472         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k=0; k&lt;columnPermutation.size(); ++k)
<a name="l00473"></a>00473             columnPermutation[k] = k;
<a name="l00474"></a>00474     }
<a name="l00475"></a>00475 
<a name="l00476"></a>00476     <span class="comment">// copy data for the recursive call in nnlassolsq</span>
<a name="l00477"></a>00477     LarsData(LarsData <span class="keyword">const</span> &amp; d, <span class="keywordtype">int</span> asetSize)
<a name="l00478"></a>00478     : activeSetSize(asetSize),
<a name="l00479"></a>00479       A(d.R.subarray(Shape(0,0), Shape(d.A.shape(0), activeSetSize))), b(d.qtb), R(A), qtb(b),
<a name="l00480"></a>00480       lars_solution(d.lars_solution.subarray(Shape(0,0), Shape(activeSetSize, 1))), lars_prediction(d.lars_prediction),
<a name="l00481"></a>00481       next_lsq_solution(d.next_lsq_solution.subarray(Shape(0,0), Shape(activeSetSize, 1))), 
<a name="l00482"></a>00482       next_lsq_prediction(d.next_lsq_prediction), searchVector(d.searchVector),
<a name="l00483"></a>00483       columnPermutation(A.shape(1))
<a name="l00484"></a>00484     {
<a name="l00485"></a>00485         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k=0; k&lt;columnPermutation.size(); ++k)
<a name="l00486"></a>00486             columnPermutation[k] = k;
<a name="l00487"></a>00487     }
<a name="l00488"></a>00488 };
<a name="l00489"></a>00489 
<a name="l00490"></a>00490 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> Array1, <span class="keyword">class</span> Array2, <span class="keyword">class</span> Array3&gt;
<a name="l00491"></a>00491 <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> 
<a name="l00492"></a>00492 leastAngleRegressionMainLoop(LarsData&lt;T, C1, C2&gt; &amp; d,
<a name="l00493"></a>00493                              Array1 &amp; activeSets, 
<a name="l00494"></a>00494                              Array2 * lars_solutions, Array3 * lsq_solutions,
<a name="l00495"></a>00495                              LeastAngleRegressionOptions <span class="keyword">const</span> &amp; options)
<a name="l00496"></a>00496 {
<a name="l00497"></a>00497     <span class="keyword">using namespace </span>vigra::functor;
<a name="l00498"></a>00498 
<a name="l00499"></a>00499     <span class="keyword">typedef</span> <span class="keyword">typename</span> MultiArrayShape&lt;2&gt;::type Shape;
<a name="l00500"></a>00500     <span class="keyword">typedef</span> <span class="keyword">typename</span> <a class="code" href="classvigra_1_1linalg_1_1Matrix.html#aacf3fd88ec09a202c9c3d22dd8288232">Matrix&lt;T&gt;::view_type</a> Subarray;
<a name="l00501"></a>00501     <span class="keyword">typedef</span> ArrayVector&lt;MultiArrayIndex&gt; Permutation;
<a name="l00502"></a>00502     <span class="keyword">typedef</span> <span class="keyword">typename</span> Permutation::view_type ColumnSet;
<a name="l00503"></a>00503 
<a name="l00504"></a>00504     vigra_precondition(d.activeSetSize &gt; 0,
<a name="l00505"></a>00505        <span class="stringliteral">&quot;leastAngleRegressionMainLoop() must not be called with empty active set.&quot;</span>);
<a name="l00506"></a>00506 
<a name="l00507"></a>00507     <span class="keywordtype">bool</span> enforce_positive = (options.mode == LeastAngleRegressionOptions::NNLASSO);
<a name="l00508"></a>00508     <span class="keywordtype">bool</span> lasso_modification = (options.mode != LeastAngleRegressionOptions::LARS);
<a name="l00509"></a>00509 
<a name="l00510"></a>00510     <span class="keyword">const</span> <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> rows = <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(d.R);
<a name="l00511"></a>00511     <span class="keyword">const</span> <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> cols = <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(d.R);
<a name="l00512"></a>00512     <span class="keyword">const</span> <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> maxRank = std::min(rows, cols);
<a name="l00513"></a>00513 
<a name="l00514"></a>00514     <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> maxSolutionCount = options.max_solution_count;
<a name="l00515"></a>00515     <span class="keywordflow">if</span>(maxSolutionCount == 0)
<a name="l00516"></a>00516         maxSolutionCount = lasso_modification
<a name="l00517"></a>00517                                 ? 10*maxRank
<a name="l00518"></a>00518                                 : maxRank;
<a name="l00519"></a>00519 
<a name="l00520"></a>00520     <span class="keywordtype">bool</span> needToRemoveColumn = <span class="keyword">false</span>;
<a name="l00521"></a>00521     <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> columnToBeAdded = 0, columnToBeRemoved = 0;
<a name="l00522"></a>00522     <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> currentSolutionCount = 0;
<a name="l00523"></a>00523     <span class="keywordflow">while</span>(currentSolutionCount &lt; maxSolutionCount)
<a name="l00524"></a>00524     {
<a name="l00525"></a>00525         <span class="comment">//ColumnSet activeSet = d.columnPermutation.subarray(0, (unsigned int)d.activeSetSize);</span>
<a name="l00526"></a>00526         ColumnSet inactiveSet = d.columnPermutation.subarray((<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>)d.activeSetSize, (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>)cols);
<a name="l00527"></a>00527 
<a name="l00528"></a>00528         <span class="comment">// find next dimension to be activated</span>
<a name="l00529"></a>00529         Matrix&lt;T&gt; cLARS = <a class="code" href="group__LinearAlgebraFunctions.html#ga38a88300083908488d85348c0cf4d3ff">transpose</a>(d.A) * (d.b - d.lars_prediction),      <span class="comment">// correlation with LARS residual</span>
<a name="l00530"></a>00530                   cLSQ  = <a class="code" href="group__LinearAlgebraFunctions.html#ga38a88300083908488d85348c0cf4d3ff">transpose</a>(d.A) * (d.b - d.next_lsq_prediction);  <span class="comment">// correlation with LSQ residual</span>
<a name="l00531"></a>00531 
<a name="l00532"></a>00532         <span class="comment">// In theory, all vectors in the active set should have the same correlation C, and</span>
<a name="l00533"></a>00533         <span class="comment">// the correlation of all others should not exceed this. In practice, we may find the</span>
<a name="l00534"></a>00534         <span class="comment">// maximum correlation in any variable due to tiny numerical inaccuracies. Therefore, we</span>
<a name="l00535"></a>00535         <span class="comment">// determine C from the entire set of variables.</span>
<a name="l00536"></a>00536         <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> cmaxIndex = enforce_positive
<a name="l00537"></a>00537                                       ? <a class="code" href="group__LinearAlgebraFunctions.html#ga19d5d885848fc3dc9364892229aaa59e" title="Find the index of the maximum element in a matrix.">argMax</a>(cLARS)
<a name="l00538"></a>00538                                       : argMax(<a class="code" href="group__LinearAlgebraFunctions.html#ga53f1096eae84afd8f97055fe7ac5c5fe">abs</a>(cLARS));
<a name="l00539"></a>00539         T C = <a class="code" href="group__LinearAlgebraFunctions.html#ga53f1096eae84afd8f97055fe7ac5c5fe">abs</a>(cLARS(cmaxIndex, 0));
<a name="l00540"></a>00540 
<a name="l00541"></a>00541         Matrix&lt;T&gt; ac(cols - d.activeSetSize, 1);
<a name="l00542"></a>00542         <span class="keywordflow">for</span>(<a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> k = 0; k&lt;cols-d.activeSetSize; ++k)
<a name="l00543"></a>00543         {
<a name="l00544"></a>00544             T rho = cLSQ(inactiveSet[k], 0), 
<a name="l00545"></a>00545               cc  = C - <a class="code" href="group__LinearAlgebraFunctions.html#ga558f5dc8c65cee5a87292d2b6f8079e3">sign</a>(rho)*cLARS(inactiveSet[k], 0);
<a name="l00546"></a>00546 
<a name="l00547"></a>00547             <span class="keywordflow">if</span>(rho == 0.0)  <span class="comment">// make sure that 0/0 cannot happen in the other cases</span>
<a name="l00548"></a>00548                 ac(k,0) = 1.0; <span class="comment">// variable k is linearly dependent on the active set</span>
<a name="l00549"></a>00549             <span class="keywordflow">else</span> <span class="keywordflow">if</span>(rho &gt; 0.0)
<a name="l00550"></a>00550                 ac(k,0) = cc / (cc + rho); <span class="comment">// variable k would enter the active set with positive sign</span>
<a name="l00551"></a>00551             <span class="keywordflow">else</span> <span class="keywordflow">if</span>(enforce_positive)
<a name="l00552"></a>00552                 ac(k,0) = 1.0; <span class="comment">// variable k cannot enter the active set because it would be negative</span>
<a name="l00553"></a>00553             <span class="keywordflow">else</span>
<a name="l00554"></a>00554                 ac(k,0) = cc / (cc - rho); <span class="comment">// variable k would enter the active set with negative sign</span>
<a name="l00555"></a>00555         }
<a name="l00556"></a>00556 
<a name="l00557"></a>00557         <span class="comment">// in the non-negative case: make sure that a column just removed cannot re-enter right away</span>
<a name="l00558"></a>00558         <span class="comment">// (in standard LASSO, this is allowed, because the variable may re-enter with opposite sign)</span>
<a name="l00559"></a>00559         <span class="keywordflow">if</span>(enforce_positive &amp;&amp; needToRemoveColumn)
<a name="l00560"></a>00560                 ac(columnToBeRemoved-d.activeSetSize,0) = 1.0;
<a name="l00561"></a>00561 
<a name="l00562"></a>00562         <span class="comment">// find candidate</span>
<a name="l00563"></a>00563         <span class="comment">// Note: R uses Arg1() &gt; epsilon, but this is only possible because it allows several variables to</span>
<a name="l00564"></a>00564         <span class="comment">//       join the active set simultaneously, so that gamma = 0 cannot occur.</span>
<a name="l00565"></a>00565         columnToBeAdded = <a class="code" href="group__LinearAlgebraFunctions.html#ga5845d7d3dbf947da264a4716d889b585" title="Find the index of the minimum element in a matrix.">argMin</a>(ac);
<a name="l00566"></a>00566 
<a name="l00567"></a>00567         <span class="comment">// if no new column can be added, we do a full step gamma = 1.0 and then stop, unless a column is removed below</span>
<a name="l00568"></a>00568         T <a class="code" href="group__MathFunctions.html#ga441c9e4bf9f952c0fe94836634bcf976" title="The gamma function.">gamma</a> = (d.activeSetSize == maxRank)
<a name="l00569"></a>00569                      ? 1.0
<a name="l00570"></a>00570                      : ac(columnToBeAdded, 0);
<a name="l00571"></a>00571 
<a name="l00572"></a>00572         <span class="comment">// adjust columnToBeAdded: we skipped the active set</span>
<a name="l00573"></a>00573         <span class="keywordflow">if</span>(columnToBeAdded &gt;= 0)
<a name="l00574"></a>00574             columnToBeAdded += d.activeSetSize;
<a name="l00575"></a>00575 
<a name="l00576"></a>00576         <span class="comment">// check whether we have to remove a column from the active set</span>
<a name="l00577"></a>00577         needToRemoveColumn = <span class="keyword">false</span>;
<a name="l00578"></a>00578         <span class="keywordflow">if</span>(lasso_modification)
<a name="l00579"></a>00579         {
<a name="l00580"></a>00580             <span class="comment">// find dimensions whose weight changes sign below gamma*searchDirection</span>
<a name="l00581"></a>00581             Matrix&lt;T&gt; s(Shape(d.activeSetSize, 1), NumericTraits&lt;T&gt;::max());
<a name="l00582"></a>00582             <span class="keywordflow">for</span>(<a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> k=0; k&lt;d.activeSetSize; ++k)
<a name="l00583"></a>00583             {
<a name="l00584"></a>00584                 <span class="keywordflow">if</span>(( enforce_positive &amp;&amp; d.next_lsq_solution(k,0) &lt; 0.0) ||
<a name="l00585"></a>00585                    (!enforce_positive &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga558f5dc8c65cee5a87292d2b6f8079e3">sign</a>(d.lars_solution(k,0))*<a class="code" href="group__LinearAlgebraFunctions.html#ga558f5dc8c65cee5a87292d2b6f8079e3">sign</a>(d.next_lsq_solution(k,0)) == -1.0))
<a name="l00586"></a>00586                         s(k,0) = d.lars_solution(k,0) / (d.lars_solution(k,0) - d.next_lsq_solution(k,0));
<a name="l00587"></a>00587             }
<a name="l00588"></a>00588 
<a name="l00589"></a>00589             columnToBeRemoved = <a class="code" href="group__LinearAlgebraFunctions.html#gaad444bde435d2eed820759f45203dfd9" title="Find the index of the minimum element in a matrix subject to a condition.">argMinIf</a>(s, Arg1() &lt;= Param(gamma));
<a name="l00590"></a>00590             <span class="keywordflow">if</span>(columnToBeRemoved &gt;= 0)
<a name="l00591"></a>00591             {
<a name="l00592"></a>00592                 needToRemoveColumn = <span class="keyword">true</span>; <span class="comment">// remove takes precedence over add</span>
<a name="l00593"></a>00593                 gamma = s(columnToBeRemoved, 0);
<a name="l00594"></a>00594             }
<a name="l00595"></a>00595         }
<a name="l00596"></a>00596 
<a name="l00597"></a>00597         <span class="comment">// compute the current solutions</span>
<a name="l00598"></a>00598         d.lars_prediction  = gamma * d.next_lsq_prediction + (1.0 - <a class="code" href="group__MathFunctions.html#ga441c9e4bf9f952c0fe94836634bcf976" title="The gamma function.">gamma</a>) * d.lars_prediction;
<a name="l00599"></a>00599         d.lars_solution    = gamma * d.next_lsq_solution   + (1.0 - gamma) * d.lars_solution;
<a name="l00600"></a>00600         <span class="keywordflow">if</span>(needToRemoveColumn)
<a name="l00601"></a>00601             d.lars_solution(columnToBeRemoved, 0) = 0.0;  <span class="comment">// turn possible epsilon into an exact zero</span>
<a name="l00602"></a>00602 
<a name="l00603"></a>00603         <span class="comment">// write the current solution</span>
<a name="l00604"></a>00604         ++currentSolutionCount;
<a name="l00605"></a>00605         activeSets.push_back(<span class="keyword">typename</span> Array1::value_type(d.columnPermutation.begin(), d.columnPermutation.begin()+d.activeSetSize));
<a name="l00606"></a>00606 
<a name="l00607"></a>00607         <span class="keywordflow">if</span>(lsq_solutions != 0)
<a name="l00608"></a>00608         {
<a name="l00609"></a>00609             <span class="keywordflow">if</span>(enforce_positive)
<a name="l00610"></a>00610             {
<a name="l00611"></a>00611                 ArrayVector&lt;Matrix&lt;T&gt; &gt; nnresults;
<a name="l00612"></a>00612                 ArrayVector&lt;ArrayVector&lt;MultiArrayIndex&gt; &gt; nnactiveSets;
<a name="l00613"></a>00613                 LarsData&lt;T, C1, C2&gt; nnd(d, d.activeSetSize);
<a name="l00614"></a>00614 
<a name="l00615"></a>00615                 leastAngleRegressionMainLoop(nnd, nnactiveSets, &amp;nnresults, (Array3*)0,
<a name="l00616"></a>00616                                              LeastAngleRegressionOptions().leastSquaresSolutions(<span class="keyword">false</span>).nnlasso());
<a name="l00617"></a>00617                 <span class="comment">//Matrix&lt;T&gt; nnlsq_solution(d.activeSetSize, 1);</span>
<a name="l00618"></a>00618                 <span class="keyword">typename</span> Array2::value_type nnlsq_solution(Shape(d.activeSetSize, 1));
<a name="l00619"></a>00619                 <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k=0; k&lt;nnactiveSets.back().size(); ++k)
<a name="l00620"></a>00620                 {
<a name="l00621"></a>00621                     nnlsq_solution(nnactiveSets.back()[k],0) = nnresults.back()[k];
<a name="l00622"></a>00622                 }
<a name="l00623"></a>00623                 <span class="comment">//lsq_solutions-&gt;push_back(nnlsq_solution);</span>
<a name="l00624"></a>00624                 lsq_solutions-&gt;push_back(<span class="keyword">typename</span> Array3::value_type());
<a name="l00625"></a>00625                 lsq_solutions-&gt;back() = nnlsq_solution;
<a name="l00626"></a>00626             }
<a name="l00627"></a>00627             <span class="keywordflow">else</span>
<a name="l00628"></a>00628             {
<a name="l00629"></a>00629                 <span class="comment">//lsq_solutions-&gt;push_back(d.next_lsq_solution.subarray(Shape(0,0), Shape(d.activeSetSize, 1)));</span>
<a name="l00630"></a>00630                 lsq_solutions-&gt;push_back(<span class="keyword">typename</span> Array3::value_type());
<a name="l00631"></a>00631                 lsq_solutions-&gt;back() = d.next_lsq_solution.subarray(Shape(0,0), Shape(d.activeSetSize, 1));
<a name="l00632"></a>00632             }
<a name="l00633"></a>00633         }
<a name="l00634"></a>00634         <span class="keywordflow">if</span>(lars_solutions != 0)
<a name="l00635"></a>00635         {
<a name="l00636"></a>00636             <span class="comment">//lars_solutions-&gt;push_back(d.lars_solution.subarray(Shape(0,0), Shape(d.activeSetSize, 1)));</span>
<a name="l00637"></a>00637             lars_solutions-&gt;push_back(<span class="keyword">typename</span> Array2::value_type());
<a name="l00638"></a>00638             lars_solutions-&gt;back() = d.lars_solution.subarray(Shape(0,0), Shape(d.activeSetSize, 1));
<a name="l00639"></a>00639         }
<a name="l00640"></a>00640 
<a name="l00641"></a>00641         <span class="comment">// no further solutions possible</span>
<a name="l00642"></a>00642         <span class="keywordflow">if</span>(gamma == 1.0)
<a name="l00643"></a>00643             <span class="keywordflow">break</span>;
<a name="l00644"></a>00644 
<a name="l00645"></a>00645         <span class="keywordflow">if</span>(needToRemoveColumn)
<a name="l00646"></a>00646         {
<a name="l00647"></a>00647             --d.activeSetSize;
<a name="l00648"></a>00648             <span class="keywordflow">if</span>(columnToBeRemoved != d.activeSetSize)
<a name="l00649"></a>00649             {
<a name="l00650"></a>00650                 <span class="comment">// remove column &#39;columnToBeRemoved&#39; and restore triangular form of R</span>
<a name="l00651"></a>00651                 <span class="comment">// note: columnPermutation is automatically swapped here</span>
<a name="l00652"></a>00652                 detail::upperTriangularSwapColumns(columnToBeRemoved, d.activeSetSize, d.R, d.qtb, d.columnPermutation);
<a name="l00653"></a>00653 
<a name="l00654"></a>00654                 <span class="comment">// swap solution entries</span>
<a name="l00655"></a>00655                 std::swap(d.lars_solution(columnToBeRemoved, 0), d.lars_solution(d.activeSetSize,0));
<a name="l00656"></a>00656                 std::swap(d.next_lsq_solution(columnToBeRemoved, 0), d.next_lsq_solution(d.activeSetSize,0));
<a name="l00657"></a>00657                 columnToBeRemoved = d.activeSetSize; <span class="comment">// keep track of removed column</span>
<a name="l00658"></a>00658             }
<a name="l00659"></a>00659             d.lars_solution(d.activeSetSize,0) = 0.0;
<a name="l00660"></a>00660             d.next_lsq_solution(d.activeSetSize,0) = 0.0;
<a name="l00661"></a>00661         }
<a name="l00662"></a>00662         <span class="keywordflow">else</span>
<a name="l00663"></a>00663         {
<a name="l00664"></a>00664             vigra_invariant(columnToBeAdded &gt;= 0,
<a name="l00665"></a>00665                 <span class="stringliteral">&quot;leastAngleRegression(): internal error (columnToBeAdded &lt; 0)&quot;</span>);
<a name="l00666"></a>00666             <span class="comment">// add column &#39;columnToBeAdded&#39;</span>
<a name="l00667"></a>00667             <span class="keywordflow">if</span>(d.activeSetSize != columnToBeAdded)
<a name="l00668"></a>00668             {
<a name="l00669"></a>00669                 std::swap(d.columnPermutation[d.activeSetSize], d.columnPermutation[columnToBeAdded]);
<a name="l00670"></a>00670                 <a class="code" href="group__LinearAlgebraFunctions.html#gab8ee32ac1c1c77108435f22be5cb08a0">columnVector</a>(d.R, d.activeSetSize).swapData(<a class="code" href="group__LinearAlgebraFunctions.html#gab8ee32ac1c1c77108435f22be5cb08a0">columnVector</a>(d.R, columnToBeAdded));
<a name="l00671"></a>00671                 columnToBeAdded = d.activeSetSize; <span class="comment">// keep track of added column</span>
<a name="l00672"></a>00672             }
<a name="l00673"></a>00673 
<a name="l00674"></a>00674             <span class="comment">// zero the corresponding entries of the solutions</span>
<a name="l00675"></a>00675             d.next_lsq_solution(d.activeSetSize,0) = 0.0;
<a name="l00676"></a>00676             d.lars_solution(d.activeSetSize,0) = 0.0;
<a name="l00677"></a>00677 
<a name="l00678"></a>00678             <span class="comment">// reduce R (i.e. its newly added column) to triangular form</span>
<a name="l00679"></a>00679             detail::qrColumnHouseholderStep(d.activeSetSize, d.R, d.qtb);
<a name="l00680"></a>00680             ++d.activeSetSize;
<a name="l00681"></a>00681         }
<a name="l00682"></a>00682 
<a name="l00683"></a>00683         <span class="comment">// compute the LSQ solution of the new active set</span>
<a name="l00684"></a>00684         Subarray Ractive = d.R.subarray(Shape(0,0), Shape(d.activeSetSize, d.activeSetSize));
<a name="l00685"></a>00685         Subarray qtbactive = d.qtb.subarray(Shape(0,0), Shape(d.activeSetSize, 1));
<a name="l00686"></a>00686         Subarray next_lsq_solution_view = d.next_lsq_solution.subarray(Shape(0,0), Shape(d.activeSetSize, 1));
<a name="l00687"></a>00687         <a class="code" href="group__MatrixAlgebra.html#ga7661f6e132de307660799727834ac25b">linearSolveUpperTriangular</a>(Ractive, qtbactive, next_lsq_solution_view);
<a name="l00688"></a>00688 
<a name="l00689"></a>00689         <span class="comment">// compute the LSQ prediction of the new active set</span>
<a name="l00690"></a>00690         d.next_lsq_prediction.init(0.0);
<a name="l00691"></a>00691         <span class="keywordflow">for</span>(<a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> k=0; k&lt;d.activeSetSize; ++k)
<a name="l00692"></a>00692             d.next_lsq_prediction += next_lsq_solution_view(k,0)*<a class="code" href="group__LinearAlgebraFunctions.html#gab8ee32ac1c1c77108435f22be5cb08a0">columnVector</a>(d.A, d.columnPermutation[k]);
<a name="l00693"></a>00693     }
<a name="l00694"></a>00694 
<a name="l00695"></a>00695     <span class="keywordflow">return</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>)currentSolutionCount;
<a name="l00696"></a>00696 }
<a name="l00697"></a>00697 
<a name="l00698"></a>00698 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> Array1, <span class="keyword">class</span> Array2&gt;
<a name="l00699"></a>00699 <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>
<a name="l00700"></a>00700 leastAngleRegressionImpl(MultiArrayView&lt;2, T, C1&gt; <span class="keyword">const</span> &amp; A, MultiArrayView&lt;2, T, C2&gt; <span class="keyword">const</span> &amp;b,
<a name="l00701"></a>00701                          Array1 &amp; activeSets, Array2 * lasso_solutions, Array2 * lsq_solutions,
<a name="l00702"></a>00702                          LeastAngleRegressionOptions <span class="keyword">const</span> &amp; options)
<a name="l00703"></a>00703 {
<a name="l00704"></a>00704     <span class="keyword">using namespace </span>vigra::functor;
<a name="l00705"></a>00705 
<a name="l00706"></a>00706     <span class="keyword">const</span> <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> rows = <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(A);
<a name="l00707"></a>00707 
<a name="l00708"></a>00708     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(b) == rows &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(b) == 1,
<a name="l00709"></a>00709        <span class="stringliteral">&quot;leastAngleRegression(): Shape mismatch between matrices A and b.&quot;</span>);
<a name="l00710"></a>00710 
<a name="l00711"></a>00711     <span class="keywordtype">bool</span> enforce_positive = (options.mode == LeastAngleRegressionOptions::NNLASSO);
<a name="l00712"></a>00712 
<a name="l00713"></a>00713     detail::LarsData&lt;T, C1, C2&gt; d(A, b);
<a name="l00714"></a>00714 
<a name="l00715"></a>00715     <span class="comment">// find dimension with largest correlation</span>
<a name="l00716"></a>00716     Matrix&lt;T&gt; c = <a class="code" href="group__LinearAlgebraFunctions.html#ga38a88300083908488d85348c0cf4d3ff">transpose</a>(A)*b;
<a name="l00717"></a>00717     <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> initialColumn = enforce_positive
<a name="l00718"></a>00718                                        ? <a class="code" href="group__LinearAlgebraFunctions.html#ga54d64ca4336ce853ea122ec56b961891" title="Find the index of the maximum element in a matrix subject to a condition.">argMaxIf</a>(c, Arg1() &gt; Param(0.0))
<a name="l00719"></a>00719                                        : argMax(<a class="code" href="group__LinearAlgebraFunctions.html#ga53f1096eae84afd8f97055fe7ac5c5fe">abs</a>(c));
<a name="l00720"></a>00720     <span class="keywordflow">if</span>(initialColumn == -1)
<a name="l00721"></a>00721         <span class="keywordflow">return</span> 0; <span class="comment">// no solution found</span>
<a name="l00722"></a>00722 
<a name="l00723"></a>00723     <span class="comment">// prepare initial active set and search direction etc.</span>
<a name="l00724"></a>00724     std::swap(d.columnPermutation[0], d.columnPermutation[initialColumn]);
<a name="l00725"></a>00725     <a class="code" href="group__LinearAlgebraFunctions.html#gab8ee32ac1c1c77108435f22be5cb08a0">columnVector</a>(d.R, 0).swapData(<a class="code" href="group__LinearAlgebraFunctions.html#gab8ee32ac1c1c77108435f22be5cb08a0">columnVector</a>(d.R, initialColumn));
<a name="l00726"></a>00726     detail::qrColumnHouseholderStep(0, d.R, d.qtb);
<a name="l00727"></a>00727     d.next_lsq_solution(0,0) = d.qtb(0,0) / d.R(0,0);
<a name="l00728"></a>00728     d.next_lsq_prediction = d.next_lsq_solution(0,0) * <a class="code" href="group__LinearAlgebraFunctions.html#gab8ee32ac1c1c77108435f22be5cb08a0">columnVector</a>(A, d.columnPermutation[0]);
<a name="l00729"></a>00729     d.searchVector = d.next_lsq_solution(0,0) * <a class="code" href="group__LinearAlgebraFunctions.html#gab8ee32ac1c1c77108435f22be5cb08a0">columnVector</a>(A, d.columnPermutation[0]);
<a name="l00730"></a>00730 
<a name="l00731"></a>00731     <span class="keywordflow">return</span> leastAngleRegressionMainLoop(d, activeSets, lasso_solutions, lsq_solutions, options);
<a name="l00732"></a>00732 }
<a name="l00733"></a>00733 
<a name="l00734"></a>00734 } <span class="comment">// namespace detail</span>
<a name="l00735"></a>00735 <span class="comment"></span>
<a name="l00736"></a>00736 <span class="comment">/** Least Angle Regression.</span>
<a name="l00737"></a>00737 <span class="comment"></span>
<a name="l00738"></a>00738 <span class="comment">       &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;&lt;br/&gt;</span>
<a name="l00739"></a>00739 <span class="comment">       Namespaces: vigra and vigra::linalg</span>
<a name="l00740"></a>00740 <span class="comment">     </span>
<a name="l00741"></a>00741 <span class="comment">       &lt;b&gt; Declarations:&lt;/b&gt;</span>
<a name="l00742"></a>00742 <span class="comment">     </span>
<a name="l00743"></a>00743 <span class="comment">       \code</span>
<a name="l00744"></a>00744 <span class="comment">       namespace vigra {</span>
<a name="l00745"></a>00745 <span class="comment">          namespace linalg {</span>
<a name="l00746"></a>00746 <span class="comment">            // compute either LASSO or least squares solutions</span>
<a name="l00747"></a>00747 <span class="comment">            template &lt;class T, class C1, class C2, class Array1, class Array2&gt;</span>
<a name="l00748"></a>00748 <span class="comment">            unsigned int</span>
<a name="l00749"></a>00749 <span class="comment">            leastAngleRegression(MultiArrayView&lt;2, T, C1&gt; const &amp; A, MultiArrayView&lt;2, T, C2&gt; const &amp;b,</span>
<a name="l00750"></a>00750 <span class="comment">                     Array1 &amp; activeSets, Array2 &amp; solutions,</span>
<a name="l00751"></a>00751 <span class="comment">                     LeastAngleRegressionOptions const &amp; options = LeastAngleRegressionOptions());</span>
<a name="l00752"></a>00752 <span class="comment"></span>
<a name="l00753"></a>00753 <span class="comment">            // compute LASSO and least squares solutions</span>
<a name="l00754"></a>00754 <span class="comment">            template &lt;class T, class C1, class C2, class Array1, class Array2&gt;</span>
<a name="l00755"></a>00755 <span class="comment">            unsigned int</span>
<a name="l00756"></a>00756 <span class="comment">            leastAngleRegression(MultiArrayView&lt;2, T, C1&gt; const &amp; A, MultiArrayView&lt;2, T, C2&gt; const &amp;b,</span>
<a name="l00757"></a>00757 <span class="comment">                     Array1 &amp; activeSets, Array2 &amp; lasso_solutions, Array2 &amp; lsq_solutions,</span>
<a name="l00758"></a>00758 <span class="comment">                     LeastAngleRegressionOptions const &amp; options = LeastAngleRegressionOptions());</span>
<a name="l00759"></a>00759 <span class="comment">          }</span>
<a name="l00760"></a>00760 <span class="comment">          using linalg::leastAngleRegression;</span>
<a name="l00761"></a>00761 <span class="comment">       }</span>
<a name="l00762"></a>00762 <span class="comment">       \endcode</span>
<a name="l00763"></a>00763 <span class="comment"></span>
<a name="l00764"></a>00764 <span class="comment">       This function implements Least Angle Regression (LARS) as described in</span>
<a name="l00765"></a>00765 <span class="comment"></span>
<a name="l00766"></a>00766 <span class="comment">       &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;</span>
<a name="l00767"></a>00767 <span class="comment">       B.Efron, T.Hastie, I.Johnstone, and R.Tibshirani: &lt;i&gt;&quot;Least Angle Regression&quot;&lt;/i&gt;,</span>
<a name="l00768"></a>00768 <span class="comment">       Annals of Statistics 32(2):407-499, 2004.</span>
<a name="l00769"></a>00769 <span class="comment"></span>
<a name="l00770"></a>00770 <span class="comment">       It is an efficient algorithm to solve the L1-regularized least squares (LASSO) problem</span>
<a name="l00771"></a>00771 <span class="comment"></span>
<a name="l00772"></a>00772 <span class="comment">        \f[ \tilde \textrm{\bf x} = \textrm{argmin}</span>
<a name="l00773"></a>00773 <span class="comment">             \left|\left|\textrm{\bf A} \textrm{\bf x} - \textrm{\bf b}\right|\right|_2^2</span>
<a name="l00774"></a>00774 <span class="comment">           \textrm{ subject to } \left|\left|\textrm{\bf x}\right|\right|_1\le s</span>
<a name="l00775"></a>00775 <span class="comment">        \f]</span>
<a name="l00776"></a>00776 <span class="comment"></span>
<a name="l00777"></a>00777 <span class="comment">       and the L1-regularized non-negative least squares (NN-LASSO) problem</span>
<a name="l00778"></a>00778 <span class="comment"></span>
<a name="l00779"></a>00779 <span class="comment">        \f[ \tilde \textrm{\bf x} = \textrm{argmin} \left|\left|\textrm{\bf A} \textrm{\bf x} - \textrm{\bf b}\right|\right|_2^2</span>
<a name="l00780"></a>00780 <span class="comment">           \textrm{ subject to } \left|\left|\textrm{\bf x}\right|\right|_1\le s \textrm{ and } \textrm{\bf x}\ge \textrm{\bf 0}</span>
<a name="l00781"></a>00781 <span class="comment">        \f]</span>
<a name="l00782"></a>00782 <span class="comment"></span>
<a name="l00783"></a>00783 <span class="comment">       where \a A is a matrix with &lt;tt&gt;m&lt;/tt&gt; rows and &lt;tt&gt;n&lt;/tt&gt; columns (often with &lt;tt&gt;m &lt; n&lt;/tt&gt;),</span>
<a name="l00784"></a>00784 <span class="comment">       \a b a vector of length &lt;tt&gt;m&lt;/tt&gt;, and a regularization parameter s &gt;= 0.0.</span>
<a name="l00785"></a>00785 <span class="comment">       L1-regularization has the desirable effect that it causes the solution &lt;b&gt;x&lt;/b&gt; to be sparse, i.e. only</span>
<a name="l00786"></a>00786 <span class="comment">       the most important elements in &lt;b&gt;x&lt;/b&gt; (called the &lt;em&gt;active set&lt;/em&gt;) have non-zero values. The</span>
<a name="l00787"></a>00787 <span class="comment">       key insight of the LARS algorithm is the following: When the solution vector &lt;b&gt;x&lt;/b&gt; is considered</span>
<a name="l00788"></a>00788 <span class="comment">       as a function of the regularization parameter s, then &lt;b&gt;x&lt;/b&gt;(s) is a piecewise</span>
<a name="l00789"></a>00789 <span class="comment">       linear function, i.e. a polyline in n-dimensional space. The knots of the polyline &lt;b&gt;x&lt;/b&gt;(s)</span>
<a name="l00790"></a>00790 <span class="comment">       are located precisely at those values of s where one variable enters or leaves the active set</span>
<a name="l00791"></a>00791 <span class="comment">       and can be efficiently computed.</span>
<a name="l00792"></a>00792 <span class="comment"></span>
<a name="l00793"></a>00793 <span class="comment">       Therefore, leastAngleRegression() returns the entire solution path as a sequence of knot points, starting</span>
<a name="l00794"></a>00794 <span class="comment">       at \f$\textrm{\bf x}(s=0)\f$ (where the only feasible solution is obviously &lt;b&gt;x&lt;/b&gt; = 0) and ending at</span>
<a name="l00795"></a>00795 <span class="comment">       \f$\textrm{\bf x}(s=\infty)\f$ (where the solution becomes the ordinary least squares solution). Actually,</span>
<a name="l00796"></a>00796 <span class="comment">       the initial null solution is not explicitly returned, i.e. the sequence starts at the first non-zero</span>
<a name="l00797"></a>00797 <span class="comment">       solution with one variable in the active set. The function leastAngleRegression() returns the number</span>
<a name="l00798"></a>00798 <span class="comment">       of solutions (i.e. knot points) computed.</span>
<a name="l00799"></a>00799 <span class="comment"></span>
<a name="l00800"></a>00800 <span class="comment">       The sequences of active sets and corresponding variable weights are returned in \a activeSets and</span>
<a name="l00801"></a>00801 <span class="comment">       \a solutions respectively. That is, &lt;tt&gt;activeSets[i]&lt;/tt&gt; is an \ref vigra::ArrayVector &quot;ArrayVector&lt;int&gt;&quot;</span>
<a name="l00802"></a>00802 <span class="comment">       containing the indices of the variables that are active at the i-th knot, and &lt;tt&gt;solutions&lt;/tt&gt; is a</span>
<a name="l00803"></a>00803 <span class="comment">       \ref vigra::linalg::Matrix &quot;Matrix&lt;T&gt;&quot; containing the weights of those variables, in the same order (see</span>
<a name="l00804"></a>00804 <span class="comment">       example below). Variables not contained in &lt;tt&gt;activeSets[i]&lt;/tt&gt; are zero at this solution.</span>
<a name="l00805"></a>00805 <span class="comment"></span>
<a name="l00806"></a>00806 <span class="comment">       The behavior of the algorithm can be adapted by \ref vigra::linalg::LeastAngleRegressionOptions</span>
<a name="l00807"></a>00807 <span class="comment">       &quot;LeastAngleRegressionOptions&quot;:</span>
<a name="l00808"></a>00808 <span class="comment">        &lt;DL&gt;</span>
<a name="l00809"></a>00809 <span class="comment">        &lt;DT&gt;&lt;b&gt;options.lasso()&lt;/b&gt; (active by default)</span>
<a name="l00810"></a>00810 <span class="comment">                          &lt;DD&gt; Compute the LASSO solution as described above.</span>
<a name="l00811"></a>00811 <span class="comment">        &lt;DT&gt;&lt;b&gt;options.nnlasso()&lt;/b&gt; (inactive by default)</span>
<a name="l00812"></a>00812 <span class="comment">                          &lt;DD&gt; Compute non-negative LASSO solutions, i.e. use the additional constraint that</span>
<a name="l00813"></a>00813 <span class="comment">                               &lt;b&gt;x&lt;/b&gt; &gt;= 0 in all solutions.</span>
<a name="l00814"></a>00814 <span class="comment">        &lt;DT&gt;&lt;b&gt;options.lars()&lt;/b&gt; (inactive by default)</span>
<a name="l00815"></a>00815 <span class="comment">                          &lt;DD&gt; Compute a solution path according to the plain LARS rule, i.e. never remove</span>
<a name="l00816"></a>00816 <span class="comment">                               a variable from the active set once it entered.</span>
<a name="l00817"></a>00817 <span class="comment">        &lt;DT&gt;&lt;b&gt;options.leastSquaresSolutions(bool)&lt;/b&gt; (default: true)</span>
<a name="l00818"></a>00818 <span class="comment">                          &lt;DD&gt; Use the algorithm mode selected above</span>
<a name="l00819"></a>00819 <span class="comment">                               to determine the sequence of active sets, but then compute and return an</span>
<a name="l00820"></a>00820 <span class="comment">                               ordinary (unconstrained) least squares solution for every active set.&lt;br&gt;</span>
<a name="l00821"></a>00821 <span class="comment">                               &lt;b&gt;Note:&lt;/b&gt; The second form of leastAngleRegression() ignores this option and</span>
<a name="l00822"></a>00822 <span class="comment">                               does always compute both constrained and unconstrained solutions (returned in</span>
<a name="l00823"></a>00823 <span class="comment">                               \a lasso_solutions and \a lsq_solutions respectively).</span>
<a name="l00824"></a>00824 <span class="comment">        &lt;DT&gt;&lt;b&gt;maxSolutionCount(unsigned int n)&lt;/b&gt; (default: n = 0, i.e. compute all solutions)</span>
<a name="l00825"></a>00825 <span class="comment">                          &lt;DD&gt; Compute at most &lt;tt&gt;n&lt;/tt&gt; solutions.</span>
<a name="l00826"></a>00826 <span class="comment">        &lt;/DL&gt;</span>
<a name="l00827"></a>00827 <span class="comment"></span>
<a name="l00828"></a>00828 <span class="comment">        &lt;b&gt;Usage:&lt;/b&gt;</span>
<a name="l00829"></a>00829 <span class="comment"></span>
<a name="l00830"></a>00830 <span class="comment">        \code</span>
<a name="l00831"></a>00831 <span class="comment">        int m = ..., n = ...;</span>
<a name="l00832"></a>00832 <span class="comment">        Matrix&lt;double&gt; A(m, n), b(m, 1);</span>
<a name="l00833"></a>00833 <span class="comment">        ... // fill A and b</span>
<a name="l00834"></a>00834 <span class="comment"></span>
<a name="l00835"></a>00835 <span class="comment">        // normalize the input</span>
<a name="l00836"></a>00836 <span class="comment">        Matrix&lt;double&gt; offset(1,n), scaling(1,n);</span>
<a name="l00837"></a>00837 <span class="comment">        prepareColumns(A, A, offset, scaling, DataPreparationGoals(ZeroMean|UnitVariance));</span>
<a name="l00838"></a>00838 <span class="comment">        prepareColumns(b, b, DataPreparationGoals(ZeroMean));</span>
<a name="l00839"></a>00839 <span class="comment"></span>
<a name="l00840"></a>00840 <span class="comment">        // arrays to hold the output</span>
<a name="l00841"></a>00841 <span class="comment">        ArrayVector&lt;ArrayVector&lt;int&gt; &gt; activeSets;</span>
<a name="l00842"></a>00842 <span class="comment">        ArrayVector&lt;Matrix&lt;double&gt; &gt; solutions;</span>
<a name="l00843"></a>00843 <span class="comment"></span>
<a name="l00844"></a>00844 <span class="comment">        // run leastAngleRegression() in non-negative LASSO mode</span>
<a name="l00845"></a>00845 <span class="comment">        int numSolutions = leastAngleRegression(A, b, activeSets, solutions,</span>
<a name="l00846"></a>00846 <span class="comment">                                    LeastAngleRegressionOptions().nnlasso());</span>
<a name="l00847"></a>00847 <span class="comment"></span>
<a name="l00848"></a>00848 <span class="comment">        // print results</span>
<a name="l00849"></a>00849 <span class="comment">        Matrix&lt;double&gt; denseSolution(1, n);</span>
<a name="l00850"></a>00850 <span class="comment">        for (MultiArrayIndex k = 0; k &lt; numSolutions; ++k)</span>
<a name="l00851"></a>00851 <span class="comment">        {</span>
<a name="l00852"></a>00852 <span class="comment">            // transform the sparse solution into a dense vector</span>
<a name="l00853"></a>00853 <span class="comment">            denseSolution.init(0.0); // ensure that inactive variables are zero</span>
<a name="l00854"></a>00854 <span class="comment">            for (unsigned int i = 0; i &lt; activeSets[k].size(); ++i)</span>
<a name="l00855"></a>00855 <span class="comment">            {</span>
<a name="l00856"></a>00856 <span class="comment">                // set the values of the active variables;</span>
<a name="l00857"></a>00857 <span class="comment">                // activeSets[k][i] is the true index of the i-th variable in the active set</span>
<a name="l00858"></a>00858 <span class="comment">                denseSolution(0, activeSets[k][i]) = solutions[k](i,0);</span>
<a name="l00859"></a>00859 <span class="comment">            }</span>
<a name="l00860"></a>00860 <span class="comment"></span>
<a name="l00861"></a>00861 <span class="comment">            // invert the input normalization</span>
<a name="l00862"></a>00862 <span class="comment">            denseSolution = denseSolution * pointWise(scaling);</span>
<a name="l00863"></a>00863 <span class="comment"></span>
<a name="l00864"></a>00864 <span class="comment">            // output the solution</span>
<a name="l00865"></a>00865 <span class="comment">            std::cout &lt;&lt; &quot;solution &quot; &lt;&lt; k &lt;&lt; &quot;:\n&quot; &lt;&lt; denseSolution &lt;&lt; std::endl;</span>
<a name="l00866"></a>00866 <span class="comment">        }</span>
<a name="l00867"></a>00867 <span class="comment">        \endcode</span>
<a name="l00868"></a>00868 <span class="comment"></span>
<a name="l00869"></a>00869 <span class="comment">        &lt;b&gt;Required Interface:&lt;/b&gt;</span>
<a name="l00870"></a>00870 <span class="comment"></span>
<a name="l00871"></a>00871 <span class="comment">        &lt;ul&gt;</span>
<a name="l00872"></a>00872 <span class="comment">        &lt;li&gt; &lt;tt&gt;T&lt;/tt&gt; must be numeric type (compatible to double)</span>
<a name="l00873"></a>00873 <span class="comment">        &lt;li&gt; &lt;tt&gt;Array1 a1;&lt;/tt&gt;&lt;br&gt;</span>
<a name="l00874"></a>00874 <span class="comment">             &lt;tt&gt;a1.push_back(ArrayVector&lt;int&gt;());&lt;/tt&gt;</span>
<a name="l00875"></a>00875 <span class="comment">        &lt;li&gt; &lt;tt&gt;Array2 a2;&lt;/tt&gt;&lt;br&gt;</span>
<a name="l00876"></a>00876 <span class="comment">             &lt;tt&gt;a2.push_back(Matrix&lt;T&gt;());&lt;/tt&gt;</span>
<a name="l00877"></a>00877 <span class="comment">        &lt;/ul&gt;</span>
<a name="l00878"></a>00878 <span class="comment">   */</span>
<a name="l00879"></a>00879 doxygen_overloaded_function(template &lt;...&gt; <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> <a class="code" href="group__Optimization.html#gab47cd570de4c39a53b4da2d830d4568c">leastAngleRegression</a>)
<a name="l00880"></a>00880 
<a name="l00881"></a>00881 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> Array1, <span class="keyword">class</span> Array2&gt;
<a name="l00882"></a>00882 <span class="keyword">inline</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>
<a name="l00883"></a>00883 <a class="code" href="group__Optimization.html#gab47cd570de4c39a53b4da2d830d4568c">leastAngleRegression</a>(MultiArrayView&lt;2, T, C1&gt; <span class="keyword">const</span> &amp; A, MultiArrayView&lt;2, T, C2&gt; <span class="keyword">const</span> &amp;b,
<a name="l00884"></a>00884                      Array1 &amp; activeSets, Array2 &amp; solutions,
<a name="l00885"></a>00885                      LeastAngleRegressionOptions <span class="keyword">const</span> &amp; options = LeastAngleRegressionOptions())
<a name="l00886"></a>00886 {
<a name="l00887"></a>00887     <span class="keywordflow">if</span>(options.least_squares_solutions)
<a name="l00888"></a>00888         <span class="keywordflow">return</span> detail::leastAngleRegressionImpl(A, b, activeSets, (Array2*)0, &amp;solutions, options);
<a name="l00889"></a>00889     <span class="keywordflow">else</span>
<a name="l00890"></a>00890         <span class="keywordflow">return</span> detail::leastAngleRegressionImpl(A, b, activeSets, &amp;solutions, (Array2*)0, options);
<a name="l00891"></a>00891 }
<a name="l00892"></a>00892 
<a name="l00893"></a>00893 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> Array1, <span class="keyword">class</span> Array2&gt;
<a name="l00894"></a>00894 <span class="keyword">inline</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span>
<a name="l00895"></a>00895 <a class="code" href="group__Optimization.html#gab47cd570de4c39a53b4da2d830d4568c">leastAngleRegression</a>(MultiArrayView&lt;2, T, C1&gt; <span class="keyword">const</span> &amp; A, MultiArrayView&lt;2, T, C2&gt; <span class="keyword">const</span> &amp;b,
<a name="l00896"></a>00896                      Array1 &amp; activeSets, Array2 &amp; lasso_solutions, Array2 &amp; lsq_solutions,
<a name="l00897"></a>00897                      LeastAngleRegressionOptions <span class="keyword">const</span> &amp; options = LeastAngleRegressionOptions())
<a name="l00898"></a>00898 {
<a name="l00899"></a>00899     <span class="keywordflow">return</span> detail::leastAngleRegressionImpl(A, b, activeSets, &amp;lasso_solutions, &amp;lsq_solutions, options);
<a name="l00900"></a>00900 }
<a name="l00901"></a>00901 <span class="comment"></span>
<a name="l00902"></a>00902 <span class="comment">   /** Non-negative Least Squares Regression.</span>
<a name="l00903"></a>00903 <span class="comment"></span>
<a name="l00904"></a>00904 <span class="comment">       Given a matrix \a A with &lt;tt&gt;m&lt;/tt&gt; rows and &lt;tt&gt;n&lt;/tt&gt; columns (with &lt;tt&gt;m &gt;= n&lt;/tt&gt;),</span>
<a name="l00905"></a>00905 <span class="comment">       and a column vector \a b of length &lt;tt&gt;m&lt;/tt&gt; rows, this function computes</span>
<a name="l00906"></a>00906 <span class="comment">       a column vector \a x of length &lt;tt&gt;n&lt;/tt&gt; with &lt;b&gt;non-negative entries&lt;/b&gt; that solves the optimization problem</span>
<a name="l00907"></a>00907 <span class="comment"></span>
<a name="l00908"></a>00908 <span class="comment">        \f[ \tilde \textrm{\bf x} = \textrm{argmin}</span>
<a name="l00909"></a>00909 <span class="comment">            \left|\left|\textrm{\bf A} \textrm{\bf x} - \textrm{\bf b}\right|\right|_2^2</span>
<a name="l00910"></a>00910 <span class="comment">            \textrm{ subject to } \textrm{\bf x} \ge \textrm{\bf 0}</span>
<a name="l00911"></a>00911 <span class="comment">        \f]</span>
<a name="l00912"></a>00912 <span class="comment"></span>
<a name="l00913"></a>00913 <span class="comment">       Both \a b and \a x must be column vectors (i.e. matrices with &lt;tt&gt;1&lt;/tt&gt; column).</span>
<a name="l00914"></a>00914 <span class="comment">       Note that all matrices must already have the correct shape. The solution is computed by means</span>
<a name="l00915"></a>00915 <span class="comment">       of \ref leastAngleRegression() with non-negativity constraint.</span>
<a name="l00916"></a>00916 <span class="comment"></span>
<a name="l00917"></a>00917 <span class="comment">       &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;</span>
<a name="l00918"></a>00918 <span class="comment">       Namespaces: vigra and vigra::linalg</span>
<a name="l00919"></a>00919 <span class="comment">   */</span>
<a name="l00920"></a>00920 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> C1, <span class="keyword">class</span> C2, <span class="keyword">class</span> C3&gt;
<a name="l00921"></a>00921 <span class="keyword">inline</span> <span class="keywordtype">void</span>
<a name="l00922"></a><a class="code" href="group__Optimization.html#ga73b680f4375cd2963543db1a7cf85e41">00922</a> <a class="code" href="group__Optimization.html#ga73b680f4375cd2963543db1a7cf85e41">nonnegativeLeastSquares</a>(<a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C1&gt;</a> <span class="keyword">const</span> &amp; A,
<a name="l00923"></a>00923                         <a class="code" href="classvigra_1_1MultiArrayView.html">MultiArrayView&lt;2, T, C2&gt;</a> <span class="keyword">const</span> &amp;b, <a class="code" href="classvigra_1_1MultiArrayView.html" title="Base class for, and view to, vigra::MultiArray.">MultiArrayView&lt;2, T, C3&gt;</a> &amp;x)
<a name="l00924"></a>00924 {
<a name="l00925"></a>00925     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(A) == <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(x) &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(A) == <a class="code" href="group__LinearAlgebraFunctions.html#gaa88b5c1277c72b4d4e2b70c278efbffe">rowCount</a>(b),
<a name="l00926"></a>00926         <span class="stringliteral">&quot;nonnegativeLeastSquares(): Matrix shape mismatch.&quot;</span>);
<a name="l00927"></a>00927     vigra_precondition(<a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(b) == 1 &amp;&amp; <a class="code" href="group__LinearAlgebraFunctions.html#ga40eab6d0fc1e179c173a3b90c9d991be">columnCount</a>(x) == 1,
<a name="l00928"></a>00928         <span class="stringliteral">&quot;nonnegativeLeastSquares(): RHS and solution must be vectors (i.e. columnCount == 1).&quot;</span>);
<a name="l00929"></a>00929 
<a name="l00930"></a>00930     <a class="code" href="classvigra_1_1ArrayVector.html">ArrayVector&lt;ArrayVector&lt;MultiArrayIndex&gt;</a> &gt; activeSets;
<a name="l00931"></a>00931     <a class="code" href="classvigra_1_1ArrayVector.html">ArrayVector&lt;Matrix&lt;T&gt;</a> &gt; results;
<a name="l00932"></a>00932 
<a name="l00933"></a>00933     <a class="code" href="group__Optimization.html#gab47cd570de4c39a53b4da2d830d4568c">leastAngleRegression</a>(A, b, activeSets, results,
<a name="l00934"></a>00934                          <a class="code" href="classvigra_1_1linalg_1_1LeastAngleRegressionOptions.html" title="Pass options to leastAngleRegression().">LeastAngleRegressionOptions</a>().leastSquaresSolutions(<span class="keyword">false</span>).nnlasso());
<a name="l00935"></a>00935     x.<a class="code" href="classvigra_1_1MultiArrayView.html#ae8d75c08347781b9854c8aea98c34610">init</a>(NumericTraits&lt;T&gt;::zero());
<a name="l00936"></a>00936     <span class="keywordflow">if</span>(activeSets.<a class="code" href="classvigra_1_1ArrayVectorView.html#a503ab01f6c0142145d3434f6924714e7">size</a>() &gt; 0)
<a name="l00937"></a>00937         <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k=0; k&lt;activeSets.<a class="code" href="classvigra_1_1ArrayVectorView.html#af71e6c1eccbc12e9339c00a86a981a43">back</a>().size(); ++k)
<a name="l00938"></a>00938             x(activeSets.<a class="code" href="classvigra_1_1ArrayVectorView.html#af71e6c1eccbc12e9339c00a86a981a43">back</a>()[k],0) = results.<a class="code" href="classvigra_1_1ArrayVectorView.html#af71e6c1eccbc12e9339c00a86a981a43">back</a>()[k];
<a name="l00939"></a>00939 }
<a name="l00940"></a>00940 
<a name="l00941"></a>00941 <span class="comment"></span>
<a name="l00942"></a>00942 <span class="comment">//@}</span>
<a name="l00943"></a>00943 <span class="comment"></span>
<a name="l00944"></a>00944 } <span class="comment">// namespace linalg</span>
<a name="l00945"></a>00945 
<a name="l00946"></a>00946 <span class="keyword">using</span> <a class="code" href="group__Optimization.html#gab3be347f5631d0aa2ee74c07479e0383">linalg::leastSquares</a>;
<a name="l00947"></a>00947 <span class="keyword">using</span> <a class="code" href="group__Optimization.html#ga591ca4f43e4114253d7bfa2953f07c4d">linalg::weightedLeastSquares</a>;
<a name="l00948"></a>00948 <span class="keyword">using</span> <a class="code" href="group__Optimization.html#ga647810e9f3f2ff2e401f410b4855c58a">linalg::ridgeRegression</a>;
<a name="l00949"></a>00949 <span class="keyword">using</span> <a class="code" href="group__Optimization.html#gade6eb7c915e0e6b1820974316b1d5d32">linalg::weightedRidgeRegression</a>;
<a name="l00950"></a>00950 <span class="keyword">using</span> <a class="code" href="group__Optimization.html#gad20a4d83649e2c65d9d553105882af9f">linalg::ridgeRegressionSeries</a>;
<a name="l00951"></a>00951 <span class="keyword">using</span> <a class="code" href="group__Optimization.html#ga73b680f4375cd2963543db1a7cf85e41">linalg::nonnegativeLeastSquares</a>;
<a name="l00952"></a>00952 <span class="keyword">using</span> <a class="code" href="group__Optimization.html#gab47cd570de4c39a53b4da2d830d4568c">linalg::leastAngleRegression</a>;
<a name="l00953"></a>00953 <span class="keyword">using</span> linalg::LeastAngleRegressionOptions;
<a name="l00954"></a>00954 
<a name="l00955"></a>00955 <span class="keyword">namespace </span>detail {
<a name="l00956"></a>00956 
<a name="l00957"></a>00957 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> S&gt;
<a name="l00958"></a>00958 <span class="keyword">inline</span> T 
<a name="l00959"></a>00959 getRow(MultiArrayView&lt;1, T, S&gt; <span class="keyword">const</span> &amp; a, <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> i)
<a name="l00960"></a>00960 {
<a name="l00961"></a>00961     <span class="keywordflow">return</span> a(i);
<a name="l00962"></a>00962 }
<a name="l00963"></a>00963 
<a name="l00964"></a>00964 <span class="keyword">template</span> &lt;<span class="keyword">class</span> T, <span class="keyword">class</span> S&gt;
<a name="l00965"></a>00965 <span class="keyword">inline</span> MultiArrayView&lt;1, T&gt;
<a name="l00966"></a>00966 getRow(MultiArrayView&lt;2, T, S&gt; <span class="keyword">const</span> &amp; a, <a class="code" href="group__MultiIteratorGroup.html#gac436173a0374e960a463a9186496ab70">MultiArrayIndex</a> i)
<a name="l00967"></a>00967 {
<a name="l00968"></a>00968     <span class="keywordflow">return</span> a.bindInner(i);
<a name="l00969"></a>00969 }
<a name="l00970"></a>00970 
<a name="l00971"></a>00971 } <span class="comment">// namespace detail</span>
<a name="l00972"></a>00972 <span class="comment"></span>
<a name="l00973"></a>00973 <span class="comment">/** \addtogroup Optimization</span>
<a name="l00974"></a>00974 <span class="comment"> */</span><span class="comment"></span>
<a name="l00975"></a>00975 <span class="comment">//@{</span>
<a name="l00976"></a>00976 <span class="comment"></span><span class="comment"></span>
<a name="l00977"></a>00977 <span class="comment">/** \brief Pass options to nonlinearLeastSquares().</span>
<a name="l00978"></a>00978 <span class="comment"></span>
<a name="l00979"></a>00979 <span class="comment">    &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;</span>
<a name="l00980"></a>00980 <span class="comment">    Namespace: vigra</span>
<a name="l00981"></a>00981 <span class="comment">*/</span>
<a name="l00982"></a><a class="code" href="classvigra_1_1NonlinearLSQOptions.html">00982</a> <span class="keyword">class </span><a class="code" href="classvigra_1_1NonlinearLSQOptions.html" title="Pass options to nonlinearLeastSquares().">NonlinearLSQOptions</a>
<a name="l00983"></a>00983 {
<a name="l00984"></a>00984   <span class="keyword">public</span>:
<a name="l00985"></a>00985   
<a name="l00986"></a>00986     <span class="keywordtype">double</span> epsilon, lambda, tau;
<a name="l00987"></a>00987     <span class="keywordtype">int</span> max_iter;
<a name="l00988"></a>00988     <span class="comment"></span>
<a name="l00989"></a>00989 <span class="comment">        /** \brief Initialize options with default values.</span>
<a name="l00990"></a>00990 <span class="comment">        */</span>
<a name="l00991"></a><a class="code" href="classvigra_1_1NonlinearLSQOptions.html#a7434a271e137c6335bc0b193c297cd7d">00991</a>     <a class="code" href="classvigra_1_1NonlinearLSQOptions.html" title="Pass options to nonlinearLeastSquares().">NonlinearLSQOptions</a>()
<a name="l00992"></a>00992     : epsilon(0.0),
<a name="l00993"></a>00993       lambda(0.1),
<a name="l00994"></a>00994       tau(1.4),
<a name="l00995"></a>00995       max_iter(50)
<a name="l00996"></a>00996     {}
<a name="l00997"></a>00997     <span class="comment"></span>
<a name="l00998"></a>00998 <span class="comment">        /** \brief Set minimum relative improvement in residual.</span>
<a name="l00999"></a>00999 <span class="comment">        </span>
<a name="l01000"></a>01000 <span class="comment">            The algorithm stops when the relative improvement in residuals</span>
<a name="l01001"></a>01001 <span class="comment">            between consecutive iterations is less than this value.</span>
<a name="l01002"></a>01002 <span class="comment">            </span>
<a name="l01003"></a>01003 <span class="comment">            Default: 0 (i.e. choose tolerance automatically, will be 10*epsilon of the numeric type)</span>
<a name="l01004"></a>01004 <span class="comment">        */</span>
<a name="l01005"></a><a class="code" href="classvigra_1_1NonlinearLSQOptions.html#affefeecb96c9406c1ade2dc2ad337e13">01005</a>     <a class="code" href="classvigra_1_1NonlinearLSQOptions.html" title="Pass options to nonlinearLeastSquares().">NonlinearLSQOptions</a> &amp; tolerance(<span class="keywordtype">double</span> eps)
<a name="l01006"></a>01006     {
<a name="l01007"></a>01007         epsilon = eps;
<a name="l01008"></a>01008         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
<a name="l01009"></a>01009     }
<a name="l01010"></a>01010     <span class="comment"></span>
<a name="l01011"></a>01011 <span class="comment">        /** \brief Set maximum number of iterations.</span>
<a name="l01012"></a>01012 <span class="comment">        </span>
<a name="l01013"></a>01013 <span class="comment">            Default: 50</span>
<a name="l01014"></a>01014 <span class="comment">        */</span>
<a name="l01015"></a><a class="code" href="classvigra_1_1NonlinearLSQOptions.html#ab28748823352d3116c4144cd280c6cad">01015</a>     <a class="code" href="classvigra_1_1NonlinearLSQOptions.html" title="Pass options to nonlinearLeastSquares().">NonlinearLSQOptions</a> &amp; maxIterations(<span class="keywordtype">int</span> iter)
<a name="l01016"></a>01016     {
<a name="l01017"></a>01017         max_iter = iter;
<a name="l01018"></a>01018         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
<a name="l01019"></a>01019     }
<a name="l01020"></a>01020     <span class="comment"></span>
<a name="l01021"></a>01021 <span class="comment">        /** \brief Set damping parameters for Levenberg-Marquardt algorithm.</span>
<a name="l01022"></a>01022 <span class="comment">        </span>
<a name="l01023"></a>01023 <span class="comment">            \a lambda determines by how much the diagonal is emphasized, and \a v is </span>
<a name="l01024"></a>01024 <span class="comment">            the factor by which lambda will be increased if more damping is needed </span>
<a name="l01025"></a>01025 <span class="comment">            for convergence</span>
<a name="l01026"></a>01026 <span class="comment">            (see &lt;a href=&quot;http://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm&quot;&gt;Wikipedia&lt;/a&gt;</span>
<a name="l01027"></a>01027 <span class="comment">            for more explanations).</span>
<a name="l01028"></a>01028 <span class="comment">        </span>
<a name="l01029"></a>01029 <span class="comment">            Default: lambda = 0.1, v = 1.4</span>
<a name="l01030"></a>01030 <span class="comment">        */</span>
<a name="l01031"></a><a class="code" href="classvigra_1_1NonlinearLSQOptions.html#ac8daebf6caa9cbbf9bcabca79a6d4d04">01031</a>     <a class="code" href="classvigra_1_1NonlinearLSQOptions.html" title="Pass options to nonlinearLeastSquares().">NonlinearLSQOptions</a> &amp; dampingParamters(<span class="keywordtype">double</span> lambda, <span class="keywordtype">double</span> v)
<a name="l01032"></a>01032     {
<a name="l01033"></a>01033         vigra_precondition(lambda &gt; 0.0 &amp;&amp; v &gt; 0.0,
<a name="l01034"></a>01034             <span class="stringliteral">&quot;NonlinearLSQOptions::dampingParamters(): parameters must be positive.&quot;</span>);
<a name="l01035"></a>01035         this-&gt;lambda = lambda;
<a name="l01036"></a>01036         tau = v;
<a name="l01037"></a>01037         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
<a name="l01038"></a>01038     }
<a name="l01039"></a>01039 };
<a name="l01040"></a>01040 
<a name="l01041"></a>01041 <span class="keyword">template</span> &lt;<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> D, <span class="keyword">class </span>T, <span class="keyword">class </span>S1, <span class="keyword">class </span>S2, 
<a name="l01042"></a>01042           <span class="keyword">class </span>U, <span class="keywordtype">int</span> N, 
<a name="l01043"></a>01043           <span class="keyword">class </span>Functor&gt;
<a name="l01044"></a>01044 T
<a name="l01045"></a>01045 nonlinearLeastSquaresImpl(MultiArrayView&lt;D, T, S1&gt; <span class="keyword">const</span> &amp; features,
<a name="l01046"></a>01046                           MultiArrayView&lt;1, T, S2&gt; <span class="keyword">const</span> &amp; response,
<a name="l01047"></a>01047                           TinyVector&lt;U, N&gt; &amp; p, 
<a name="l01048"></a>01048                           Functor model,
<a name="l01049"></a>01049                           NonlinearLSQOptions <span class="keyword">const</span> &amp; options)
<a name="l01050"></a>01050 {
<a name="l01051"></a>01051     vigra_precondition(features.shape(0) == response.shape(0),
<a name="l01052"></a>01052                        <span class="stringliteral">&quot;nonlinearLeastSquares(): shape mismatch between features and response.&quot;</span>);
<a name="l01053"></a>01053                        
<a name="l01054"></a>01054     <span class="keywordtype">double</span> t = options.tau, l = options.lambda;  <span class="comment">// initial damping parameters</span>
<a name="l01055"></a>01055     
<a name="l01056"></a>01056     <span class="keywordtype">double</span> epsilonT = NumericTraits&lt;T&gt;::epsilon()*10.0,
<a name="l01057"></a>01057            epsilonU = NumericTraits&lt;U&gt;::epsilon()*10.0,
<a name="l01058"></a>01058            epsilon = options.epsilon &lt;= 0.0
<a name="l01059"></a>01059                          ? std::max(epsilonT, epsilonU)
<a name="l01060"></a>01060                          : options.epsilon;
<a name="l01061"></a>01061     
<a name="l01062"></a>01062     linalg::Matrix&lt;T&gt; jj(N,N);  <span class="comment">// outer product of the Jacobian</span>
<a name="l01063"></a>01063     TinyVector&lt;U, N&gt; jr, dp;
<a name="l01064"></a>01064     
<a name="l01065"></a>01065     T residual = 0.0;
<a name="l01066"></a>01066     <span class="keywordtype">bool</span> didStep = <span class="keyword">true</span>;
<a name="l01067"></a>01067     
<a name="l01068"></a>01068     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> iter=0; iter&lt;options.max_iter; ++iter)
<a name="l01069"></a>01069     {
<a name="l01070"></a>01070         <span class="keywordflow">if</span>(didStep)
<a name="l01071"></a>01071         {
<a name="l01072"></a>01072             <span class="comment">// update the residual and Jacobian</span>
<a name="l01073"></a>01073             residual = 0.0;
<a name="l01074"></a>01074             jr = 0.0;
<a name="l01075"></a>01075             jj = 0.0;
<a name="l01076"></a>01076             
<a name="l01077"></a>01077             <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0; i&lt;features.shape(0); ++i)
<a name="l01078"></a>01078             {
<a name="l01079"></a>01079                 autodiff::DualVector&lt;U, N&gt; res = model(detail::getRow(features, i), autodiff::dualMatrix(p));
<a name="l01080"></a>01080                 
<a name="l01081"></a>01081                 T r = response(i) - res.v;
<a name="l01082"></a>01082                 jr += r * res.d;
<a name="l01083"></a>01083                 jj += <a class="code" href="group__LinearAlgebraFunctions.html#ga6f6a862ad62cb16aa66d9ec7329d696c">outer</a>(res.d);
<a name="l01084"></a>01084                 residual += <a class="code" href="group__LinearAlgebraFunctions.html#ga9ab478f0a88c5174f28260163a1a6de9">sq</a>(r);
<a name="l01085"></a>01085             }
<a name="l01086"></a>01086         }
<a name="l01087"></a>01087         
<a name="l01088"></a>01088         <span class="comment">// perform a damped gradient step</span>
<a name="l01089"></a>01089         linalg::Matrix&lt;T&gt; djj(jj);
<a name="l01090"></a>01090         djj.diagonal() *= 1.0 + l;        
<a name="l01091"></a>01091         <a class="code" href="group__MatrixAlgebra.html#ga889fc66edb20976e31a9212a073e411f">linearSolve</a>(djj, jr, dp);
<a name="l01092"></a>01092         
<a name="l01093"></a>01093         TinyVector&lt;U, N&gt; p_new = p + dp;
<a name="l01094"></a>01094         
<a name="l01095"></a>01095         <span class="comment">// compute the new residual</span>
<a name="l01096"></a>01096         T residual_new = 0.0;
<a name="l01097"></a>01097         <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=0; i&lt;features.shape(0); ++i)
<a name="l01098"></a>01098         {
<a name="l01099"></a>01099             residual_new += <a class="code" href="group__LinearAlgebraFunctions.html#ga9ab478f0a88c5174f28260163a1a6de9">sq</a>(response(i) - model(detail::getRow(features, i), p_new));
<a name="l01100"></a>01100         }
<a name="l01101"></a>01101         
<a name="l01102"></a>01102         <span class="keywordflow">if</span>(residual_new &lt; residual)
<a name="l01103"></a>01103         {
<a name="l01104"></a>01104             <span class="comment">// accept the step</span>
<a name="l01105"></a>01105             p = p_new;
<a name="l01106"></a>01106             <span class="keywordflow">if</span>(<a class="code" href="group__FFTWComplexOperators.html#ga6f4ef274842b6153923f02a6cd264576" title="absolute value (= magnitude)">std::abs</a>((residual - residual_new) / residual) &lt; epsilon)
<a name="l01107"></a>01107                 <span class="keywordflow">return</span> residual_new;
<a name="l01108"></a>01108             <span class="comment">// try less damping in the next iteration</span>
<a name="l01109"></a>01109             l /= t;
<a name="l01110"></a>01110             didStep = <span class="keyword">true</span>;
<a name="l01111"></a>01111         }
<a name="l01112"></a>01112         <span class="keywordflow">else</span>
<a name="l01113"></a>01113         {
<a name="l01114"></a>01114             <span class="comment">// reject the step und use more damping in the next iteration</span>
<a name="l01115"></a>01115             l *= t;
<a name="l01116"></a>01116             didStep = <span class="keyword">false</span>;
<a name="l01117"></a>01117         }
<a name="l01118"></a>01118     }
<a name="l01119"></a>01119     
<a name="l01120"></a>01120     <span class="keywordflow">return</span> residual;
<a name="l01121"></a>01121 }
<a name="l01122"></a>01122 
<a name="l01123"></a>01123 <span class="comment">/********************************************************/</span>
<a name="l01124"></a>01124 <span class="comment">/*                                                      */</span>
<a name="l01125"></a>01125 <span class="comment">/*                 nonlinearLeastSquares                */</span>
<a name="l01126"></a>01126 <span class="comment">/*                                                      */</span>
<a name="l01127"></a>01127 <span class="comment">/********************************************************/</span>
<a name="l01128"></a>01128 <span class="comment"></span>
<a name="l01129"></a>01129 <span class="comment">/** \brief Fit a non-linear model to given data by minimizing least squares loss.</span>
<a name="l01130"></a>01130 <span class="comment"></span>
<a name="l01131"></a>01131 <span class="comment">    &lt;b&gt; Declarations:&lt;/b&gt;</span>
<a name="l01132"></a>01132 <span class="comment">    </span>
<a name="l01133"></a>01133 <span class="comment">    \code</span>
<a name="l01134"></a>01134 <span class="comment">    namespace vigra {</span>
<a name="l01135"></a>01135 <span class="comment">        // variant 1: optimize a univariate model (&#39;x&#39; is a 1D array of scalar data points)</span>
<a name="l01136"></a>01136 <span class="comment">        template &lt;class T, class S1, class S2, </span>
<a name="l01137"></a>01137 <span class="comment">                  class U, int N, </span>
<a name="l01138"></a>01138 <span class="comment">                  class Functor&gt;</span>
<a name="l01139"></a>01139 <span class="comment">        T</span>
<a name="l01140"></a>01140 <span class="comment">        nonlinearLeastSquares(MultiArrayView&lt;1, T, S1&gt; const &amp; x,</span>
<a name="l01141"></a>01141 <span class="comment">                              MultiArrayView&lt;1, T, S2&gt; const &amp; y,</span>
<a name="l01142"></a>01142 <span class="comment">                              TinyVector&lt;U, N&gt; &amp; model_parameters, </span>
<a name="l01143"></a>01143 <span class="comment">                              Functor model,</span>
<a name="l01144"></a>01144 <span class="comment">                              NonlinearLSQOptions const &amp; options = NonlinearLSQOptions());</span>
<a name="l01145"></a>01145 <span class="comment"></span>
<a name="l01146"></a>01146 <span class="comment">        // variant 2: optimize a multivariate model (&#39;x&#39; is a 2D array of vector-valued data points)</span>
<a name="l01147"></a>01147 <span class="comment">        template &lt;class T, class S1, class S2, </span>
<a name="l01148"></a>01148 <span class="comment">                  class U, int N, </span>
<a name="l01149"></a>01149 <span class="comment">                  class Functor&gt;</span>
<a name="l01150"></a>01150 <span class="comment">        T</span>
<a name="l01151"></a>01151 <span class="comment">        nonlinearLeastSquares(MultiArrayView&lt;2, T, S1&gt; const &amp; x,</span>
<a name="l01152"></a>01152 <span class="comment">                              MultiArrayView&lt;1, T, S2&gt; const &amp; y,</span>
<a name="l01153"></a>01153 <span class="comment">                              TinyVector&lt;U, N&gt; &amp; model_parameters, </span>
<a name="l01154"></a>01154 <span class="comment">                              Functor model,</span>
<a name="l01155"></a>01155 <span class="comment">                              NonlinearLSQOptions const &amp; options = NonlinearLSQOptions());</span>
<a name="l01156"></a>01156 <span class="comment">    }</span>
<a name="l01157"></a>01157 <span class="comment">    \endcode</span>
<a name="l01158"></a>01158 <span class="comment">    </span>
<a name="l01159"></a>01159 <span class="comment">    This function implements the </span>
<a name="l01160"></a>01160 <span class="comment">    &lt;a href=&quot;http://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm&quot;&gt;Levenberg-Marquardt algorithm&lt;/a&gt;</span>
<a name="l01161"></a>01161 <span class="comment">    to fit a non-linear model to given data. The model depends on a vector of </span>
<a name="l01162"></a>01162 <span class="comment">    parameters &lt;b&gt;p&lt;/b&gt; which are to be choosen such that the least-squares residual </span>
<a name="l01163"></a>01163 <span class="comment">    between the data and the model&#39;s predictions is minimized according to the objective function:</span>
<a name="l01164"></a>01164 <span class="comment"></span>
<a name="l01165"></a>01165 <span class="comment">    \f[ \tilde \textrm{\bf p} = \textrm{argmin}_{\textrm{\bf p}} \sum_i \left( y_i - f(\textrm{\bf x}_i; \textrm{\bf p}) \right)^2</span>
<a name="l01166"></a>01166 <span class="comment">    \f]</span>
<a name="l01167"></a>01167 <span class="comment"></span>
<a name="l01168"></a>01168 <span class="comment">    where \f$f(\textrm{\bf x}; \textrm{\bf p})\f$ is the model to be optimized </span>
<a name="l01169"></a>01169 <span class="comment">    (with arguments \f$\textrm{\bf x}\f$ and parameters \f$\textrm{\bf p}\f$), and </span>
<a name="l01170"></a>01170 <span class="comment">    \f$(\textrm{\bf x}_i; y_i)\f$ are the feature/response pairs of the given data. </span>
<a name="l01171"></a>01171 <span class="comment">    Since the model is non-linear (otherwise, you should use ordinary \ref leastSquares()), </span>
<a name="l01172"></a>01172 <span class="comment">    it must be linearized in terms of a first-order Taylor expansion, and the optimal </span>
<a name="l01173"></a>01173 <span class="comment">    parameters &lt;b&gt;p&lt;/b&gt; have to be determined iteratively. In order for the iterations to </span>
<a name="l01174"></a>01174 <span class="comment">    converge to the desired solution, a good initial guess on &lt;b&gt;p&lt;/b&gt; is required.</span>
<a name="l01175"></a>01175 <span class="comment">    </span>
<a name="l01176"></a>01176 <span class="comment">    The model must be specified by a functor which takes one of the following forms:</span>
<a name="l01177"></a>01177 <span class="comment">    \code</span>
<a name="l01178"></a>01178 <span class="comment">    typedef double DataType;   // type of your data samples, may be any numeric type</span>
<a name="l01179"></a>01179 <span class="comment">    static const int N = ...;  // number of model parameters</span>
<a name="l01180"></a>01180 <span class="comment">    </span>
<a name="l01181"></a>01181 <span class="comment">    // variant 1: the features x are scalars</span>
<a name="l01182"></a>01182 <span class="comment">    struct UnivariateModel </span>
<a name="l01183"></a>01183 <span class="comment">    {</span>
<a name="l01184"></a>01184 <span class="comment">        template &lt;class T&gt;</span>
<a name="l01185"></a>01185 <span class="comment">        T operator()(DataType x, TinyVector&lt;T, N&gt; const &amp; p) const { ... }</span>
<a name="l01186"></a>01186 <span class="comment">    };</span>
<a name="l01187"></a>01187 <span class="comment">    </span>
<a name="l01188"></a>01188 <span class="comment">    // variant 2: the features x are vectors</span>
<a name="l01189"></a>01189 <span class="comment">    struct MultivariateModel</span>
<a name="l01190"></a>01190 <span class="comment">    {</span>
<a name="l01191"></a>01191 <span class="comment">        template &lt;class T&gt;</span>
<a name="l01192"></a>01192 <span class="comment">        T operator()(MultiArrayView&lt;1, DataType&gt; const &amp; x, TinyVector&lt;T, N&gt; const &amp; p) const { ... }</span>
<a name="l01193"></a>01193 <span class="comment">    };</span>
<a name="l01194"></a>01194 <span class="comment">    \endcode</span>
<a name="l01195"></a>01195 <span class="comment">    Each call to the functor&#39;s &lt;tt&gt;operator()&lt;/tt&gt; computes the model&#39;s prediction for a single data</span>
<a name="l01196"></a>01196 <span class="comment">    point. The current model parameters are specified in a TinyVector of appropriate length. </span>
<a name="l01197"></a>01197 <span class="comment">    The type &lt;tt&gt;T&lt;/tt&gt; must be templated: normally, it is the same as &lt;tt&gt;DataType&lt;/tt&gt;, but</span>
<a name="l01198"></a>01198 <span class="comment">    the nonlinearLeastSquares() function will temporarily replace it with a special number type</span>
<a name="l01199"></a>01199 <span class="comment">    that supports &lt;a href=&quot;http://en.wikipedia.org/wiki/Automatic_differentiation&quot;&gt;automatic differentiation&lt;/a&gt; </span>
<a name="l01200"></a>01200 <span class="comment">    (see \ref vigra::autodiff::DualVector). In this way, the derivatives needed in the model&#39;s Taylor </span>
<a name="l01201"></a>01201 <span class="comment">    expansion can be computed automatically.</span>
<a name="l01202"></a>01202 <span class="comment">    </span>
<a name="l01203"></a>01203 <span class="comment">    When the model is univariate (has a single scalar argument), the samples must be passed to </span>
<a name="l01204"></a>01204 <span class="comment">    nonlinearLeastSquares() in a pair &#39;x&#39;, &#39;y&#39; of 1D &lt;tt&gt;MultiArrayView&lt;/tt&gt;s (variant 1).</span>
<a name="l01205"></a>01205 <span class="comment">    When the model is multivariate (has a vector-valued argument), the &#39;x&#39; input must</span>
<a name="l01206"></a>01206 <span class="comment">    be a 2D &lt;tt&gt;MultiArrayView&lt;/tt&gt; (variant 2) whose rows represent a single data sample </span>
<a name="l01207"></a>01207 <span class="comment">    (i.e. the number of columns corresponds to the length of the model&#39;s argument vector). </span>
<a name="l01208"></a>01208 <span class="comment">    The number of rows in &#39;x&#39; defines the number of data samples and must match the length</span>
<a name="l01209"></a>01209 <span class="comment">    of array &#39;y&#39;.</span>
<a name="l01210"></a>01210 <span class="comment">    </span>
<a name="l01211"></a>01211 <span class="comment">    The &lt;tt&gt;TinyVector&lt;/tt&gt; &#39;model_parameters&#39; holds the initial guess for the model parameters and</span>
<a name="l01212"></a>01212 <span class="comment">    will be overwritten by the optimal values found by the algorithm. The algorithm&#39;s internal behavior</span>
<a name="l01213"></a>01213 <span class="comment">    can be controlled by customizing the option object \ref vigra::NonlinearLSQOptions. </span>
<a name="l01214"></a>01214 <span class="comment">    </span>
<a name="l01215"></a>01215 <span class="comment">    The function returns the residual sum of squared errors of the final solution.</span>
<a name="l01216"></a>01216 <span class="comment">    </span>
<a name="l01217"></a>01217 <span class="comment">    &lt;b&gt; Usage:&lt;/b&gt;</span>
<a name="l01218"></a>01218 <span class="comment">    </span>
<a name="l01219"></a>01219 <span class="comment">    &lt;b&gt;\#include&lt;/b&gt; &lt;vigra/regression.hxx&gt;&lt;br&gt;</span>
<a name="l01220"></a>01220 <span class="comment">    Namespace: vigra</span>
<a name="l01221"></a>01221 <span class="comment">    </span>
<a name="l01222"></a>01222 <span class="comment">    Suppose that we want to fit a centered Gaussian function of the form</span>
<a name="l01223"></a>01223 <span class="comment">    \f[ f(x ; a, s, b) = a \exp\left(-\frac{x^2}{2 s^2}\right) + b  \f]</span>
<a name="l01224"></a>01224 <span class="comment">    to noisy data \f$(x_i, y_i)\f$, i.e. we want to find parameters a, s, b such that</span>
<a name="l01225"></a>01225 <span class="comment">    the residual \f$\sum_i \left(y_i - f(x_i; a,s,b)\right)^2\f$ is minimized.</span>
<a name="l01226"></a>01226 <span class="comment">    The model parameters are placed in a &lt;tt&gt;TinyVector&lt;T, 3&gt;&lt;/tt&gt; &lt;b&gt;p&lt;/b&gt; according to the rules&lt;br/&gt;</span>
<a name="l01227"></a>01227 <span class="comment">    &lt;tt&gt;p[0] &lt;=&gt; a&lt;/tt&gt;, &lt;tt&gt;p[1] &lt;=&gt; s&lt;/tt&gt; and &lt;tt&gt;p[2] &lt;=&gt; b&lt;/tt&gt;.&lt;br/&gt; The following</span>
<a name="l01228"></a>01228 <span class="comment">    functor computes the model&#39;s prediction for a single data point &lt;tt&gt;x&lt;/tt&gt;:</span>
<a name="l01229"></a>01229 <span class="comment">    \code</span>
<a name="l01230"></a>01230 <span class="comment">    struct GaussianModel</span>
<a name="l01231"></a>01231 <span class="comment">    {</span>
<a name="l01232"></a>01232 <span class="comment">        template &lt;class T&gt;</span>
<a name="l01233"></a>01233 <span class="comment">        T operator()(double x, TinyVector&lt;T, 3&gt; const &amp; p) const</span>
<a name="l01234"></a>01234 <span class="comment">        {</span>
<a name="l01235"></a>01235 <span class="comment">            return p[0] * exp(-0.5 * sq(x / p[1])) + p[2];</span>
<a name="l01236"></a>01236 <span class="comment">        }</span>
<a name="l01237"></a>01237 <span class="comment">    };</span>
<a name="l01238"></a>01238 <span class="comment">    \endcode</span>
<a name="l01239"></a>01239 <span class="comment">    Now we can find optimal values for the parameters like this:</span>
<a name="l01240"></a>01240 <span class="comment">    \code</span>
<a name="l01241"></a>01241 <span class="comment">    int size = ...;  // number of data points</span>
<a name="l01242"></a>01242 <span class="comment">    MultiArray&lt;1, double&gt; x(size), y(size);    </span>
<a name="l01243"></a>01243 <span class="comment">    ...   // fill the data arrays</span>
<a name="l01244"></a>01244 <span class="comment">    </span>
<a name="l01245"></a>01245 <span class="comment">    TinyVector&lt;double, 3&gt; p(2.0, 1.0, 0.5);  // your initial guess of the parameters</span>
<a name="l01246"></a>01246 <span class="comment">                                             // (will be overwritten with the optimal values)</span>
<a name="l01247"></a>01247 <span class="comment">    double residual = nonlinearLeastSquares(x, y, p, GaussianModel());</span>
<a name="l01248"></a>01248 <span class="comment">    </span>
<a name="l01249"></a>01249 <span class="comment">    std::cout &lt;&lt; &quot;Model parameters: a=&quot; &lt;&lt; p[0] &lt;&lt; &quot;, s=&quot; &lt;&lt; p[1] &lt;&lt; &quot;, b=&quot; &lt;&lt; p[2] &lt;&lt; &quot; (residual: &quot; &lt;&lt; residual &lt;&lt; &quot;)\n&quot;;</span>
<a name="l01250"></a>01250 <span class="comment">    \endcode</span>
<a name="l01251"></a>01251 <span class="comment">*/</span>
<a name="l01252"></a>01252 doxygen_overloaded_function(template &lt;...&gt; <span class="keywordtype">void</span> <a class="code" href="group__Optimization.html#gaca08304f34fff2a829234d2c374f4252" title="Fit a non-linear model to given data by minimizing least squares loss.">nonlinearLeastSquares</a>)
<a name="l01253"></a>01253 
<a name="l01254"></a>01254 <span class="keyword">template</span> &lt;<span class="keyword">class </span>T, <span class="keyword">class </span>S1, <span class="keyword">class </span>S2, 
<a name="l01255"></a>01255           <span class="keyword">class </span>U, <span class="keywordtype">int</span> N, 
<a name="l01256"></a>01256           <span class="keyword">class </span>Functor&gt;
<a name="l01257"></a>01257 <span class="keyword">inline</span> T
<a name="l01258"></a>01258 <a class="code" href="group__Optimization.html#gaca08304f34fff2a829234d2c374f4252" title="Fit a non-linear model to given data by minimizing least squares loss.">nonlinearLeastSquares</a>(MultiArrayView&lt;1, T, S1&gt; <span class="keyword">const</span> &amp; features,
<a name="l01259"></a>01259                       MultiArrayView&lt;1, T, S2&gt; <span class="keyword">const</span> &amp; response,
<a name="l01260"></a>01260                       TinyVector&lt;U, N&gt; &amp; p, 
<a name="l01261"></a>01261                       Functor model,
<a name="l01262"></a>01262                       NonlinearLSQOptions <span class="keyword">const</span> &amp; options = NonlinearLSQOptions())
<a name="l01263"></a>01263 {
<a name="l01264"></a>01264     <span class="keywordflow">return</span> nonlinearLeastSquaresImpl(features, response, p, model, options);
<a name="l01265"></a>01265 }
<a name="l01266"></a>01266 
<a name="l01267"></a>01267 <span class="keyword">template</span> &lt;<span class="keyword">class </span>T, <span class="keyword">class </span>S1, <span class="keyword">class </span>S2, 
<a name="l01268"></a>01268           <span class="keyword">class </span>U, <span class="keywordtype">int</span> N, 
<a name="l01269"></a>01269           <span class="keyword">class </span>Functor&gt;
<a name="l01270"></a>01270 <span class="keyword">inline</span> T
<a name="l01271"></a>01271 <a class="code" href="group__Optimization.html#gaca08304f34fff2a829234d2c374f4252" title="Fit a non-linear model to given data by minimizing least squares loss.">nonlinearLeastSquares</a>(MultiArrayView&lt;2, T, S1&gt; <span class="keyword">const</span> &amp; features,
<a name="l01272"></a>01272                       MultiArrayView&lt;1, T, S2&gt; <span class="keyword">const</span> &amp; response,
<a name="l01273"></a>01273                       TinyVector&lt;U, N&gt; &amp; p, 
<a name="l01274"></a>01274                       Functor model,
<a name="l01275"></a>01275                       NonlinearLSQOptions <span class="keyword">const</span> &amp; options = NonlinearLSQOptions())
<a name="l01276"></a>01276 {
<a name="l01277"></a>01277     <span class="keywordflow">return</span> nonlinearLeastSquaresImpl(features, response, p, model, options);
<a name="l01278"></a>01278 }
<a name="l01279"></a>01279 <span class="comment"></span>
<a name="l01280"></a>01280 <span class="comment">//@}</span>
<a name="l01281"></a>01281 <span class="comment"></span>
<a name="l01282"></a>01282 } <span class="comment">// namespace vigra</span>
<a name="l01283"></a>01283 
<a name="l01284"></a>01284 <span class="preprocessor">#endif // VIGRA_REGRESSION_HXX</span>
</pre></div></div><!-- contents -->
<!-- footer.html -->
<p>
<table border=0 cellspacing=0 width="100%"  bgcolor="#e0d0a0" cellpadding=5>
<tr>
<td>
<p>
<i>&copy; <A HREF="http://hci.iwr.uni-heidelberg.de/people/ukoethe/">Ullrich K&ouml;the</A>     (<A
HREF="mailto:ullrich.koethe@iwr.uni-heidelberg.de">ullrich.koethe@iwr.uni-heidelberg.de</A>)</i> <br>
<i><A HREF="http://hci.iwr.uni-heidelberg.de/">
Heidelberg Collaboratory for Image Processing</a>,
University of Heidelberg, Germany</i>
<td>
<p align=right>
<I>html generated using <A HREF="http://www.doxygen.org">doxygen</A> and <A HREF="http://www.python.org">Python</A></I>
<br>
<i>
vigra 1.9.1 (Thu Sep 5 2013)
</i>
</tr>
</table>


</BODY>
</HTML>
